{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 12 - Causal decisions and reinforcement learning\n",
        "\n",
        "The notebook is a code companion to chapter 12 of the book [Causal AI](https://www.manning.com/books/causal-ai) by [Robert Osazuwa Ness](https://www.linkedin.com/in/osazuwa/). This code is aligned with the code in the text.\n",
        "\n",
        "<a href=\"https://github.com/altdeep/causalML/blob/master/book/chapter%2012/chapter_12_causal_decision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "39G_Dg8ot-f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGwC-t-VMtFX",
        "outputId": "b4882eab-49a1-4ba6-f323-d41997437c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.24 in /usr/local/lib/python3.10/dist-packages (0.1.24)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (2.0.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (2.3.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy==0.1.24) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.24) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.24) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pgmpy==0.1.24) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy==0.1.24) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy==0.1.24) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy==0.1.24) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pgmpy==0.1.24"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.1 DAG for investment decision model\n",
        "\n",
        "A major source of confusion for causal decision modeling is the difference between actions and interventions. In many decision contexts, especially in reinforcement learning, the action is a thing that the agent does that changes their environment. Yet, the action is also a variable driven by the environment. We see this when we look again at the investment example:\n",
        "\n",
        "![investment DAG](https://github.com/altdeep/causalML/blob/master/book/chapter%2012/images/investment.png?raw=true)\n",
        "\n",
        "Most conventional approaches to decision-making, including in reinforcement learning, focus on maximizing E(U(Y)|X=x) rather than $E(U(Y_{X=x}))$."
      ],
      "metadata": {
        "id": "KI-kM27lubKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE1qfdF9Myyv",
        "outputId": "3d8d9b4c-1cbf-4618-9dc7-8e1053932f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.24 in /usr/local/lib/python3.10/dist-packages (0.1.24)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (2.0.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (2.3.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy==0.1.24) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy==0.1.24) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy==0.1.24) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.24) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy==0.1.24) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy==0.1.24) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pgmpy==0.1.24) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy==0.1.24) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy==0.1.24) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy==0.1.24) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pgmpy==0.1.24\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "import numpy as np\n",
        "\n",
        "model = BayesianNetwork([    #A\n",
        "    ('C', 'X'),    #A\n",
        "    ('C', 'Y'),    #A\n",
        "    ('X', 'Y'),    #A\n",
        "    ('Y', 'U')    #A\n",
        "])    #A\n",
        "#A Setup the DAG"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.2 Create causal Markov kernels for C, X, and Y\n",
        "\n",
        "Next we build the causal Markov kernels for Economy (C), Debt v. Equity (X), and business success (Y)."
      ],
      "metadata": {
        "id": "7j9yl0HFvvr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HieUnx4_M3tr"
      },
      "outputs": [],
      "source": [
        "cpd_c = TabularCPD(    #A\n",
        "    variable='C',    #A\n",
        "    variable_card=2,    #A\n",
        "    values=[[0.5], [0.5]],    #A\n",
        "    state_names={'C': ['bear', 'bull']}    #A\n",
        ")    #A\n",
        "\n",
        "cpd_x = TabularCPD(    #B\n",
        "    variable='X',    #B\n",
        "    variable_card=2,    #B\n",
        "    values=[[0.8, 0.2], [0.2, 0.8]],    #B\n",
        "    evidence=['C'],    #B\n",
        "    evidence_card=[2],    #B\n",
        "    state_names={'X': ['debt', 'equity'], 'C': ['bear', 'bull']}    #B\n",
        ")    #B\n",
        "\n",
        "cpd_y = TabularCPD(    #C\n",
        "    variable='Y',    #C\n",
        "    variable_card=2,    #C\n",
        "    values= [[0.3, 0.9, 0.7, 0.6], [0.7, 0.1, 0.3, 0.4]],    #C\n",
        "    evidence=['X', 'C'],    #C\n",
        "    evidence_card=[2, 2],    #C\n",
        "    state_names={    #C\n",
        "        'Y': ['failure', 'success'],    #C\n",
        "        'X': ['debt', 'equity'],    #C\n",
        "        'C': ['bear', 'bull']    #C\n",
        "    }    #C\n",
        ")    #C\n",
        "#A Setup causal Markov kernel for C (economy). It takes two values \"bull\" (good economic conditions) and \"bear\" bad economic conditions.\n",
        "#B Setup causal Markov kernel for action X, either making a debt investment or equity investment. Historic analysis shows investors prefer equity investing in a bull market and debt investment in a bear market.\n",
        "#C Setup causal Markov kernel for business outcome Y, either success or failure, depending on the type of investment provided (X), and the economy Y.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.3 Implement the utility node and initialize the model\n",
        "\n",
        "Finally, we add the utility node U. We use probabilities of 1 and 0 to represent a deterministic function of Y. We end by adding all the kernels to the model."
      ],
      "metadata": {
        "id": "9I7WgYQwwauT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpd_u = TabularCPD(    #A\n",
        "    variable='U',    #A\n",
        "    variable_card=2,    #A\n",
        "    values=[[1., 0.], [0., 1.]],    #E\n",
        "    evidence=['Y'],    #A\n",
        "    evidence_card=[2],    #A\n",
        "    state_names={'U': [-1000, 99000], 'Y': ['failure', 'success']}    #A\n",
        ")    #A\n",
        "print(cpd_u)    #A\n",
        "model.add_cpds(cpd_c, cpd_x, cpd_y, cpd_u)\n",
        "#A Setup the utility node.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpMSnXYQwn_B",
        "outputId": "3e61b7f8-9229-4c6a-b6d4-ab622cdb08ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+------------+\n",
            "| Y        | Y(failure) | Y(success) |\n",
            "+----------+------------+------------+\n",
            "| U(-1000) | 1.0        | 0.0        |\n",
            "+----------+------------+------------+\n",
            "| U(99000) | 0.0        | 1.0        |\n",
            "+----------+------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.4 Download helper function for implementing an ideal intervention\n",
        "\n",
        "Before proceeding, download and load a helper function that implements an ideal intervention. To allay security concerns of directly executing download code, the logic displays the script and prompts you to confirm before executing."
      ],
      "metadata": {
        "id": "ri0DPe0Hw0Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/altdeep/causalML/master/book/pgmpy_do.py\"   #A\n",
        "response = requests.get(url)   #A\n",
        "content = response.text   #A\n",
        "\n",
        "print(\"Downloaded script content:\\n\")    #B\n",
        "print(content)    #B\n",
        "confirm = input(\"\\nDo you want to execute this script? (yes/no): \")    #B\n",
        "if confirm.lower() == 'yes':    #B\n",
        "    exec(content)    #B\n",
        "else:    #B\n",
        "    print(\"Script execution cancelled.\")    #B\n",
        "#A Load an implementation of an ideal intervention.\n",
        "#B To allay security concerns, you can inspect the downloaded script and confirm before running.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiiRCqb0w1C-",
        "outputId": "fe6c1c0a-7813-4e17-9979-ebf0c4b0d3a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded script content:\n",
            "\n",
            "from pgmpy.models import BayesianNetwork\n",
            "from pgmpy.factors.discrete import TabularCPD\n",
            "\n",
            "\n",
            "def do(model: BayesianNetwork, interventions: dict):\n",
            "    \"\"\" \n",
            "    Implement an ideal intervention for discrete variables. Modifies pgmpy's\n",
            "    `do` method so it is a `do`-operator, meaning a function that takes in a\n",
            "    model, modifies it with an ideal intervention, and returns a new model.\n",
            "    Note that this code would need to be modified to work for continuous\n",
            "    variables.\n",
            "    \"\"\"\n",
            "    def _mod_kernel(kernel: TabularCPD, int_val):\n",
            "        \"\"\"\n",
            "        Modify a causal Markov kernel so all probability is on the state fixed\n",
            "        by the intervention.\n",
            "        \"\"\" \n",
            "        var_name = kernel.variable\n",
            "        card = kernel.get_cardinality([var_name])[var_name]\n",
            "        states = [kernel.get_state_names(var_name, i) for i in range(card)]\n",
            "        non_int_states = set(states) - {int_val,}\n",
            "        unordered_prob_vals = [[1.0]] + [[0.0] for _ in range(card - 1)]\n",
            "        unordered_states = [int_val] + list(non_int_states)\n",
            "        # Reorder so it matches original\n",
            "        dict_ = dict(zip(unordered_states, unordered_prob_vals))\n",
            "        ordered_prob_values = [dict_[k] for k in states]\n",
            "        intervention_kernel = TabularCPD(\n",
            "            var_name, card, ordered_prob_values,\n",
            "            state_names = {var_name: states}\n",
            "        )\n",
            "        return intervention_kernel\n",
            "\n",
            "    kernels = {kern.variable: kern for kern in model.get_cpds()}\n",
            "    new_model = model.copy()\n",
            "    for var, int_val in interventions.items():\n",
            "        new_model = new_model.do(var)\n",
            "        new_kernel = _mod_kernel(kernels[var], int_val)\n",
            "        new_model.add_cpds(new_kernel)\n",
            "    return new_model\n",
            "    \n",
            "\n",
            "\n",
            "Do you want to execute this script? (yes/no): yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.5 Calculate E(U(Y)|X=x) and $E(U(Y_{X=x}))$\n",
        "\n",
        "By now in this book, you should not be surprised that $E(U(Y_{X=x}))$ is different from E(U(Y)|X=x). Let’s look at these values."
      ],
      "metadata": {
        "id": "dee7MlWzxBOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_expectation(marginal):    #A\n",
        "    utility_values = marginal.state_names[\"U\"]    #A\n",
        "    probabilities = marginal.values    #A\n",
        "    expectation = sum([x * p for x, p in zip(utility_values, probabilities)])    #A\n",
        "    return expectation    #A\n",
        "\n",
        "infer = VariableElimination(model)    #B\n",
        "marginal_u_given_debt = infer.query(variables=['U'], evidence={'X': 'debt'})    #B\n",
        "marginal_u_given_equity = infer.query(variables=['U'], evidence={'X': 'equity'})    #B\n",
        "e_u_given_x_debt = get_expectation(marginal_u_given_debt)    #B\n",
        "e_u_given_x_equity = get_expectation(marginal_u_given_equity)    #B\n",
        "print(\"E(U(Y)|X=debt)=\", e_u_given_x_debt)    #B\n",
        "print(\"E(U(Y)|X=equity)=\", e_u_given_x_equity)    #B\n",
        "\n",
        "int_model_x_debt = do(model, {\"X\": \"debt\"})    #C\n",
        "infer_debt = VariableElimination(int_model_x_debt)    #C\n",
        "marginal_u_given_debt = infer_debt.query(variables=['U'])    #C\n",
        "expectation_u_given_debt = get_expectation(marginal_u_given_debt)    #C\n",
        "print(\"E(U(Y_{X=debt}))=\", expectation_u_given_debt)    #C\n",
        "int_model_x_equity = do(model, {\"X\": \"equity\"})    #C\n",
        "infer_equity = VariableElimination(int_model_x_equity)    #C\n",
        "marginal_u_given_equity = infer_equity.query(variables=['U'])    #C\n",
        "expectation_u_given_equity = get_expectation(marginal_u_given_equity)    #C\n",
        "print(\"E(U(Y_{X=equity}))=\", expectation_u_given_equity)    #C\n",
        "#A A helper function for calculating the expected utility.\n",
        "#B Set X by intervention to debt and equity and calculate the expectation of U under each intervention.\n",
        "#C Condition on X = debt and X = equity and calculate the expectation of U.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoi3CL11xBUD",
        "outputId": "5a59f726-98f4-49ee-9c2d-5c18bacfe44b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:Replacing existing CPD for X\n",
            "WARNING:pgmpy:Replacing existing CPD for X\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E(U(Y)|X=debt)= 56999.99999999999\n",
            "E(U(Y)|X=equity)= 37000.00000000001\n",
            "E(U(Y_{X=debt}))= 39000.0\n",
            "E(U(Y_{X=equity}))= 34000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us the following conditional expected utilities (I mark the highest with *):\n",
        "\n",
        "* $E(U(Y)|X=debt)$ = 57000.0 *\n",
        "*\t$E(U(Y)|X=equity)$ = 37000.0\n",
        "\n",
        "And the following interventional expected utilities.\n",
        "\n",
        "*\t$E(U(Y_{X=debt}))$ = 39000.0 *\n",
        "*\t$E(U(Y_{X=equity}))$ = 34000.0\n",
        "\n",
        "So E(U(Y)|X=debt) is different from $E(U(Y_{X=\\text{debt}}))$ and $E(U(Y)|X=equity)$ is different from $E(U(Y_{X=\\text{equity}}))$. However, our goal is to optimize expected utility. And in this case, debt maximizes both $E(U(Y)|X=x)$ and $E(U(Y_{X=x}))$.\n",
        "\n",
        "$\\text{argmax}_x E(U(Y_{X=x}))$\n",
        "\n",
        "= $\\text{argmax}_x E(U(Y|X=x))$\n",
        "\n",
        "= \"debt\"\n",
        "\n",
        "If \"debt\" maximizes both queries, what is the point of causal decision theory? What does it matter if $E(U(Y)|X=x)$ and $E(U(Y_{X=x}))$ are different if the optimal action for both is the same?\n",
        "\n",
        "In decision problems, it is quite common that a causal formulation of the problem provides the same answer as more traditional non-causal formulations. This is especially true in higher dimensional problems common in reinforcement learning. Some observe this and wonder why the causal formulation is needed at all.\n",
        "\n",
        "## Listing 12.6 Change a parameter in causal Markov kernel for Y\n",
        "\n",
        "To answer, watch what happens when we make a slight change to the parameters of Y in the model. Specifically, we'll change the parameter for P(Y=success|X=equity, C=bull) from .4 to .6. First, we'll rebuild the model with the parameter change."
      ],
      "metadata": {
        "id": "PI7DpjNxxcy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = BayesianNetwork([    #A\n",
        "    ('C', 'X'),    #A\n",
        "    ('C', 'Y'),    #A\n",
        "    ('X', 'Y'),    #A\n",
        "    ('Y', 'U')    #A\n",
        "])\n",
        "\n",
        "cpd_y2 = TabularCPD(    #B\n",
        "    variable='Y',\n",
        "    variable_card=2,\n",
        "    values=[[0.3, 0.9, 0.7, 0.4],  [0.7, 0.1, 0.3, 0.6]],    #C\n",
        "    evidence=['X', 'C'],\n",
        "    evidence_card=[2, 2],\n",
        "    state_names={\n",
        "        'Y': ['failure', 'success'],\n",
        "        'X': ['debt', 'equity'],\n",
        "        'C': ['bear', 'bull']\n",
        "    }\n",
        ")\n",
        "\n",
        "model2.add_cpds(cpd_c, cpd_x, cpd_y2, cpd_u)    #D\n",
        "#A Initialize a new model\n",
        "#B Create a new conditional probability distribution for Y\n",
        "#C Change the parameter P(Y=success|X=equity, C=bull) = 0.4 (the last parameter in the first list) to 0.6.\n",
        "#D Add the causal Markov kernels to the model."
      ],
      "metadata": {
        "id": "WQ8JdAIwyos4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.7 Compare outcomes with changed parameters\n",
        "\n",
        "Next, we rerun inference."
      ],
      "metadata": {
        "id": "v_fLAfDuygbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer = VariableElimination(model2)    #A\n",
        "marginal_u_given_debt = infer.query(variables=['U'], evidence={'X': 'debt'})    #A\n",
        "marginal_u_given_equity = infer.query(variables=['U'], evidence={'X': 'equity'})    #A\n",
        "e_u_given_x_debt = get_expectation(marginal_u_given_debt)    #A\n",
        "e_u_given_x_equity = get_expectation(marginal_u_given_equity)    #A\n",
        "print(\"E(U(Y)|X=debt)=\", e_u_given_x_debt)    #A\n",
        "print(\"E(U(Y)|X=equity)=\", e_u_given_x_equity)    #A\n",
        "\n",
        "int_model_x_debt = do(model2, {\"X\": \"debt\"})    #B\n",
        "infer_debt = VariableElimination(int_model_x_debt)    #B\n",
        "marginal_u_given_debt = infer_debt.query(variables=['U'])    #B\n",
        "expectation_u_given_debt = get_expectation(marginal_u_given_debt)    #B\n",
        "print(\"E(U(Y_{X=debt}))=\", expectation_u_given_debt)    #B\n",
        "int_model_x_equity = do(model2, {\"X\": \"equity\"})    #B\n",
        "infer_equity = VariableElimination(int_model_x_equity)    #B\n",
        "marginal_u_given_equity = infer_equity.query(variables=['U'])    #B\n",
        "expectation_u_given_equity = get_expectation(marginal_u_given_equity)    #B\n",
        "print(\"E(U(Y_{X=equity}))=\", expectation_u_given_equity)    #B\n",
        "#A Set X by intervention to debt and equity and calculate the expectation of U under each intervention.\n",
        "#B Condition on X = debt and X = equity and calculate the expectation of U.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDk0B4b5y1zv",
        "outputId": "dcfcf5a2-fe71-4a4b-f7cb-a046e18c8d7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:Replacing existing CPD for X\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E(U(Y)|X=debt)= 56999.99999999999\n",
            "E(U(Y)|X=equity)= 53000.0\n",
            "E(U(Y_{X=debt}))="
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:Replacing existing CPD for X\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 39000.0\n",
            "E(U(Y_{X=equity}))= 43999.99999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us the following conditional expectations (* indicates the optimal choice).\n",
        "\n",
        "* E(U(Y)|X=debt) = 57000.0 *\n",
        "* E(U(Y)|X=equity) = 53000.0\n",
        "\n",
        "And the following interventional expectations.\n",
        "\n",
        "*\t$E(U(Y_{X=debt}))$ = 39000.0\n",
        "*\t$E(U(Y_{X=equity}))$ = 44000.0 *\n",
        "\n",
        "With that slight change in a single parameter, “debt” is still the optimal value of x in  $E(U(Y)|X=x)$ but now “equity” is the optimal value of x in $E(U(Y_{X=x}))$. This is a case where the causal answer and the answer from conditioning on evidence are different. And since we are trying to answer a level 2 query, the causal approach is the right approach.\n",
        "\n",
        "This means that while simply optimizing a conditional expectation often gets you the right answer, you are vulnerable to getting the wrong answer in certain circumstances. Compare this to our discussion of semi-supervised learning in Chapter 4; often the unlabeled data can help with learning, but in specific causal circumstances, the unlabeled data adds no value. Similarly, in this case, there are specific causal scenarios where the causal formulation of the problem will provide a different and more correct result relative to the traditional non-causal formulation. Even the most popular decision-optimization algorithms, including the deep learning-based approaches used in deep reinforcement learning, can get the answer wrong if they fail to account for the causal structure of the problem.\n"
      ],
      "metadata": {
        "id": "Y0pBb58My9hO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7OZKOV_KItL"
      },
      "source": [
        "# Newcomb's Paradox Example\n",
        "\n",
        "A famous thought experiment called Newcomb's paradox contrasts the causal approach to decision theory, maximizing utility under intervention, with the conventional approach of maximizing utility conditional on some action. First, I present an AI-inspired version of this thought experiment, and show how to approach it with a formal causal model.\n",
        "\n",
        "There are two boxes designated A and B. Box A always contains \\$1,000. Box B contains either \\$1,000,000 or \\$0. The decision-making agent must choose between taking only box B or both boxes. The agent does not know what is in box B until they decide. Given this information, it is obvious the agent should take both boxes – choosing both yields either \\$1,000 or \\$1,001,000, while choosing only B yields either \\$0 or \\$1,000,000.\n",
        "\n",
        "Now, suppose there is an AI that can predict with high accuracy what choice the agent intends to make. If the AI predicts the agent intends to take both boxes, it will put no money in box B. If the AI is correct, the agent only gets \\$1,000. If the AI predicts that the agent intends to take only box B, it will put \\$1,000,000 in box B. If the AI predicts correctly, the agent gets the \\$1,000,000 in box B but not the \\$1,000 in box A. The agent does not know for sure what the AI predicted or what box B contains until they make their choice.\n",
        "\n",
        "![Newcomb](https://github.com/altdeep/causalML/blob/master/book/chapter%2012/images/newcomb.png?raw=true)\n",
        "\n",
        "\n",
        "The paradox arises as follows. If the agent goes with the conventional approach of maximizing expected utility conditional on its choice, the optimal choice is different. We can see that by enumerating the possible outcomes and their probabilities. Let's assume the AI's predictions are 95% accurate. If the agent chooses both boxes, there is a 95% chance the AI will have guessed the agent's choice and put no money in B, in which case the agent only gets the \\$1,000. There is a 5% chance the algorithm will guess wrong, in which case it puts \\$1,000,000 in box B, and the agent wins \\$1,001,000. If the agent chooses only box B, there is a 95% chance the AI will have predicted the choice and placed \\$1,000,000 in box B, given the agent \\$1,000,000 in winnings. There is a 5% chance it will not, and the agent will take home nothing.\n",
        "\n",
        "In the traditional formulation of Newcomb's paradox, the assumption is that the agent using causal decision theory only attends to the consequences of their actions, i.e., they are reasoning on the following causal DAG.\n",
        "\n",
        "![Newcomb naive DAG](https://github.com/altdeep/causalML/blob/master/book/chapter%2012/images/newcomb%20dag.png?raw=true)\n",
        "\n",
        "But the true data generating process is better captured by the following DAG:\n",
        "\n",
        "![Necomb complete DAG](https://github.com/altdeep/causalML/blob/master/book/chapter%2012/images/newcomb%20DAG%202.png?raw=true)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.8 Create the DAG\n",
        "\n",
        "First, we build the DAG."
      ],
      "metadata": {
        "id": "E2eYtFKmQCao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BayesianNetwork(    #A\n",
        "    [    #A\n",
        "        ('intent', 'AI prediction'),    #A\n",
        "        ('intent', 'choice'),    #A\n",
        "        ('AI prediction', 'box B'),    #A\n",
        "        ('choice', 'U'),    #A\n",
        "        ('box B', 'U'),    #A\n",
        "    ]    #A\n",
        ")    #A\n",
        "#A Create the DAG"
      ],
      "metadata": {
        "id": "uPPJej3mELa0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.9 Create causal Markov kernels for intent and choice\n",
        "\n",
        "Next, we create causal Markov kernels for intent and choice."
      ],
      "metadata": {
        "id": "rhbXwXmQQRVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpd_intent = TabularCPD(    #A\n",
        "    'intent', 2, [[0.5], [.5]],    #A\n",
        "    state_names={'intent': ['B', 'both']}    #A\n",
        ")    #A\n",
        "print(cpd_intent)\n",
        "\n",
        "cpd_choice = TabularCPD(    #B\n",
        "    'choice', 2, [[1, 0], [0, 1]],    #B\n",
        "    evidence=['intent'],     #B\n",
        "    evidence_card=[2],    #B\n",
        "    state_names={    #B\n",
        "        'choice': ['B', 'both'],    #B\n",
        "        'intent': ['B', 'both']    #B\n",
        "    }    #B\n",
        ")    #B\n",
        "print(cpd_choice)\n",
        "#A We assume a 50-50 chance the agent will prefer both boxes vs box B.\n",
        "#B We assume the agent's choice is deterministically driven by their intent."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlvR1LSNEfpG",
        "outputId": "da4d9b6f-9f9f-4337-9d8a-2bcebd834772"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "| intent(B)    | 0.5 |\n",
            "+--------------+-----+\n",
            "| intent(both) | 0.5 |\n",
            "+--------------+-----+\n",
            "+--------------+-----------+--------------+\n",
            "| intent       | intent(B) | intent(both) |\n",
            "+--------------+-----------+--------------+\n",
            "| choice(B)    | 1.0       | 0.0          |\n",
            "+--------------+-----------+--------------+\n",
            "| choice(both) | 0.0       | 1.0          |\n",
            "+--------------+-----------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.9 Create causal Markov kernels for AI prediction and box B content\n",
        "\n",
        "Similarly, we create the causal Markov kernels for the AI's decision and the content of box B.\n"
      ],
      "metadata": {
        "id": "CvLYtad7QjfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpd_AI = TabularCPD(    #A\n",
        "    'AI prediction', 2, [[.95, 0.05], [.05, .95]],    #A\n",
        "    evidence=['intent'],    #A\n",
        "    evidence_card=[2],    #A\n",
        "    state_names={    #A\n",
        "        'AI prediction': ['B', 'both'],    #A\n",
        "        'intent': ['B', 'both']    #A\n",
        "    }    #A\n",
        ")    #A\n",
        "print(cpd_AI)\n",
        "\n",
        "cpd_box_b_content = TabularCPD(    #B\n",
        "    'box B', 2, [[0, 1], [1, 0]],    #B\n",
        "    evidence=['AI prediction'],    #B\n",
        "    evidence_card=[2],    #B\n",
        "    state_names={    #B\n",
        "        'box B': [0, 1000000],    #B\n",
        "        'AI prediction': ['B', 'both']    #B\n",
        "    }    #B\n",
        ")    #B\n",
        "print(cpd_box_b_content)\n",
        "#A The AI's prediction is 95% accurate\n",
        "#B Box B contents are set deterministically by the AI's prediction."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_gaDsDCE8RI",
        "outputId": "e9198c45-9498-4c06-f70a-3967f0898014"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----------+--------------+\n",
            "| intent              | intent(B) | intent(both) |\n",
            "+---------------------+-----------+--------------+\n",
            "| AI prediction(B)    | 0.95      | 0.05         |\n",
            "+---------------------+-----------+--------------+\n",
            "| AI prediction(both) | 0.05      | 0.95         |\n",
            "+---------------------+-----------+--------------+\n",
            "+----------------+------------------+---------------------+\n",
            "| AI prediction  | AI prediction(B) | AI prediction(both) |\n",
            "+----------------+------------------+---------------------+\n",
            "| box B(0)       | 0.0              | 1.0                 |\n",
            "+----------------+------------------+---------------------+\n",
            "| box B(1000000) | 1.0              | 0.0                 |\n",
            "+----------------+------------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.10 Create utility kernel and build the model\n"
      ],
      "metadata": {
        "id": "RvD_qre3Q7-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpd_u = TabularCPD(    #A\n",
        "    'U', 4,    #A\n",
        "    [    #A\n",
        "        [1, 0, 0, 0],    #A\n",
        "        [0, 1, 0, 0],    #A\n",
        "        [0, 0, 1, 0],    #A\n",
        "        [0, 0, 0, 1],    #A\n",
        "    ],    #A\n",
        "    evidence=['box B', 'choice'],    #A\n",
        "    evidence_card=[2, 2],    #A\n",
        "    state_names={    #A\n",
        "        'U': [0, 1000, 1000000, 1001000],    #A\n",
        "        'box B': [0, 1000000],    #A\n",
        "        'choice': ['B', 'both']    #A\n",
        "    }    #A\n",
        ")    #A\n",
        "print(cpd_u)\n",
        "\n",
        "model.add_cpds(cpd_intent, cpd_choice, cpd_AI, cpd_box_b_content, cpd_u)     #B\n",
        "\n",
        "#A Setup the utility node.\n",
        "#B Build the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxIK0UgoEin9",
        "outputId": "031288c0-a205-4787-8998-e4810c22bc8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| box B      | box B(0)  | box B(0)     | box B(1000000) | box B(1000000) |\n",
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| choice     | choice(B) | choice(both) | choice(B)      | choice(both)   |\n",
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| U(0)       | 1.0       | 0.0          | 0.0            | 0.0            |\n",
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| U(1000)    | 0.0       | 1.0          | 0.0            | 0.0            |\n",
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| U(1000000) | 0.0       | 0.0          | 1.0            | 0.0            |\n",
            "+------------+-----------+--------------+----------------+----------------+\n",
            "| U(1001000) | 0.0       | 0.0          | 0.0            | 1.0            |\n",
            "+------------+-----------+--------------+----------------+----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing 12.11 Infer optimal choice using intervention and conditioning on intent\n",
        "\n",
        "The choice of the agent can't cause the AI's prediction, because the prediction happens first. Thus, we assume the AI agent is inferring the agents intent, and thus the intent of the agent is the cause of the AI's prediction.\n",
        "The causal decision-making agent would prefer the latter graph because it is a better representation of the data generating process. The clever agent wouldn't focus on maximizing $E(U_{choice=x})$. The clever agent is aware of its own intention. Knowing that this intention is a cause of the contents of box B, it focuses on optimizing $E(U_{choice=x}|intent=i)$, where i is their original intention of which box to pick.\n",
        "\n",
        "$\\text{argmax}_x E(U_{choice=x}|intent=i)$\n",
        "\n",
        "We'll assume the agent's initial intention is an impulse it cannot control. But while they can't control their initial intent, they can do some introspection and become aware of this intent. Further, we'll assume that upon doing so they have the ability to change its choice to something different from what it initially intended after the AI has made its prediction and set the contents of box B. Let's model this system in pgmpy and evaluate maximizing $E(U_{choice=x}|intent=i)$."
      ],
      "metadata": {
        "id": "MEFAuKo7RMJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_model_x_both = do(model, {\"choice\": \"both\"})    #A\n",
        "infer_both = VariableElimination(int_model_x_both)    #A\n",
        "marginal_u_given_both = infer_both.query(variables=['U'], evidence={'intent': 'both'})    #A\n",
        "expectation_u_given_both = get_expectation(marginal_u_given_both)    #A\n",
        "print(\"E(U(Y_{choice=both}|intent=both))=\", expectation_u_given_both)    #A\n",
        "int_model_x_box_B = do(model, {\"choice\": \"B\"})    #B\n",
        "infer_box_B = VariableElimination(int_model_x_box_B)    #B\n",
        "marginal_u_given_box_B = infer_box_B.query(variables=['U'], evidence={'intent': 'both'})    #B\n",
        "expectation_u_given_box_B = get_expectation(marginal_u_given_box_B)    #B\n",
        "print(\"E(U(Y_{choice=box B}|intent=both))=\", expectation_u_given_box_B)    #B\n",
        "int_model_x_both = do(model, {\"choice\": \"both\"})    #C\n",
        "infer_both = VariableElimination(int_model_x_both)    #C\n",
        "marginal_u_given_both = infer_both.query(variables=['U'], evidence={'intent': 'B'})    #C\n",
        "expectation_u_given_both = get_expectation(marginal_u_given_both)    #C\n",
        "print(\"E(U(Y_{choice=both}|intent=B))=\", expectation_u_given_both)    #C\n",
        "int_model_x_box_B = do(model, {\"choice\": \"B\"})    #D\n",
        "infer_box_B = VariableElimination(int_model_x_box_B)    #D\n",
        "marginal_u_given_box_B = infer_box_B.query(variables=['U'], evidence={'intent': 'B'})    #D\n",
        "expectation_u_given_box_B = get_expectation(marginal_u_given_box_B)    #D\n",
        "print(\"E(U(Y_{choice=box B}|intent=B))=\", expectation_u_given_box_B)    #D\n",
        "#A Infer E(U(Ychoice=both|intent=both))\n",
        "#B Infer E(U(Ychoice=box B|intent=both))\n",
        "#C Infer E(U(Ychoice=both|intent=B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llhzdyMU2l6O",
        "outputId": "037bbafa-9b1d-416c-8c09-aa6012ae970a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:Replacing existing CPD for choice\n",
            "WARNING:pgmpy:Replacing existing CPD for choice\n",
            "WARNING:pgmpy:Replacing existing CPD for choice\n",
            "WARNING:pgmpy:Replacing existing CPD for choice\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E(U(Y_{choice=both}|intent=both))= 51000.0\n",
            "E(U(Y_{choice=box B}|intent=both))= 50000.0\n",
            "E(U(Y_{choice=both}|intent=B))= 951000.0\n",
            "E(U(Y_{choice=box B}|intent=B))= 950000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code produces the following results (* indicates the optimal choice for a given intent):\n",
        "\n",
        "*\t$E(U(Y_{choice=both}|intent=both))$= 51000.0 *\n",
        "*\t$E(U(Y_{choice=box B}|intent=both))$= 50000.0\n",
        "*\t$E(U(Y_{choice=both}|intent=B))$= 951000.0 *\n",
        "*\t$E(U(Y_{choice=box B}|intent=B))$= 950000.0\n",
        "\n",
        "When the agent's initial intention is to select both, the best choice is to select both. When the agent intends to choose only box B, the best choice is to ignore those intentions and choose both. Either way, the agent should choose both. Note that when the agent happens to initially intends to choose only box B, switching to both boxes gives them an expected utility of 951000.0, which is greater than the optimal choice utility of 950000 in the non-causal approach.\n"
      ],
      "metadata": {
        "id": "rsZm6_wy2m2U"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}