{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Ymgsl3bG3v"
      },
      "source": [
        "# Chapter 11 - Bayesian Causal Effect Graphical Inference\n",
        "\n",
        "The notebook is a code companion to chapter 11 of the book [Causal AI](https://www.manning.com/books/causal-ai) by [Robert Osazuwa Ness](https://www.linkedin.com/in/osazuwa/). This code is aligned with the code in the text.\n",
        "\n",
        "<a href=\"https://github.com/altdeep/causalML/blob/master/book/chapter%2011/Chapter_11_Bayesian_Causal_Graphical_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Eum-SOvrY1x"
      },
      "outputs": [],
      "source": [
        "!pip install pyro-ppl==1.9\n",
        "!pip install graphviz==0.20\n",
        "!pip install pandas==1.5.3\n",
        "!pip install torch==2.2.1+cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2c0jD0orY1z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/altdeep/causalML/master/datasets/online_game_ate.csv\")    #A\n",
        "df = df[[\"Guild Membership\", \"Side-quest Engagement\", \"Won Items\", \"In-game Purchases\"]]   #B\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    #C\n",
        "data = {    #C\n",
        "    col: torch.tensor(df[col].values, dtype=torch.float32).to(device)    #C\n",
        "    for col in df.columns    #C\n",
        "}    #C\n",
        "\n",
        "\n",
        "#A Load the data.\n",
        "#B Drop everything but Guild Membership, Side-quest Engagement, Won Items, In-game Purchases.\n",
        "#C Convert the data to tensors and dynamically set the device for performing tensor computations depending on the availability of a CUDA-enabled GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJYbqx92rY1z"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Confounders2Engagement(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim=1+1,    #A\n",
        "        hidden_dim=5    #B\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)   #C\n",
        "        self.f_engagement_ρ = nn.Linear(hidden_dim, 1)    #D\n",
        "        self.softplus = nn.Softplus()    #E\n",
        "        self.sigmoid = nn.Sigmoid()    #F\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        hidden = self.softplus(self.fc1(input))    #G\n",
        "        ρ_engagement = self.sigmoid(self.f_engagement_ρ(hidden))    #H\n",
        "        ρ_engagement = ρ_engagement.t().squeeze(0)\n",
        "        return ρ_engagement\n",
        "\n",
        "#A Input is confounder proxy Z concatenated with Guild Membership.\n",
        "#B Choosing a hidden dimension of width 5.\n",
        "#C Linear map from input to hidden dimension.\n",
        "#D Linear map from hidden dimension to In-Game Purchases location parameter.\n",
        "#E Activation function for hidden layer.\n",
        "#F Activation function for Side-quest engagement parameter.\n",
        "#G From input to hidden layer\n",
        "#H From hidden layer to ρ_engagement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah4VcT2srY10"
      },
      "outputs": [],
      "source": [
        "class PurchasesNetwork(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim=1+1+1,    #A\n",
        "        hidden_dim=5    #B\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.f_hidden = nn.Linear(input_dim, hidden_dim)   #C\n",
        "        self.f_purchase_μ = nn.Linear(hidden_dim, 1)    #D\n",
        "        self.f_purchase_σ = nn.Linear(hidden_dim, 1)    #E\n",
        "        self.softplus = nn.Softplus()    #F\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        hidden = self.softplus(self.f_hidden(input))    #G\n",
        "        μ_purchases = self.f_purchase_μ(hidden)   #H\n",
        "        σ_purchases = 1e-6 + self.softplus(self.f_purchase_σ(hidden))    #I\n",
        "        μ_purchases = μ_purchases.t().squeeze(0)\n",
        "        σ_purchases = σ_purchases.t().squeeze(0)\n",
        "        return μ_purchases, σ_purchases\n",
        "\n",
        "#A Input is confounder proxy Z concatenated with Guild Membership and Won Items.\n",
        "#B Choosing a hidden dimension of width 5.\n",
        "#C Linear map from input to hidden dimension.\n",
        "#D Linear map from hidden dimension to In-Game Purchases location parameter.\n",
        "#E Linear map from hidden dimension to In-Game Purchases location parameter.\n",
        "#F Activation function for hidden layer.\n",
        "#G From input to hidden layer.\n",
        "#H Mapping from hidden layer to location parameter for purchases.\n",
        "#I Mapping from hidden layer scale parameter for purchases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i84fJmPiuo9o"
      },
      "outputs": [],
      "source": [
        "from pyro import sample\n",
        "from pyro.distributions import Bernoulli, Normal\n",
        "from torch import tensor, stack\n",
        "\n",
        "\n",
        "def model(params, device=device):    #A\n",
        "    z = sample(\"Z\", Normal(tensor(0.0, device=device), tensor(1.0, device=device)))\n",
        "    is_guild_member = sample(\"Guild Membership\", Bernoulli(params['ρ_member']))    #C\n",
        "    engagement_input = stack((is_guild_member, z)).to(device)   #D\n",
        "    ρ_engagement = confounders_2_engagement(engagement_input)    #D\n",
        "    is_highly_engaged = sample(\"Side-quest Engagement\", Bernoulli(ρ_engagement))    #E\n",
        "    p_won = (    #F\n",
        "        params['ρ_won_engaged'] * is_highly_engaged +    #F\n",
        "        params['ρ_won_not_engaged'] * (1 - is_highly_engaged)    #F\n",
        "    )    #F\n",
        "    won_items = sample(\"Won Items\", Bernoulli(p_won))    #F\n",
        "    purchase_input = stack((won_items, is_guild_member, z)).to(device)    #G\n",
        "    μ_purchases, σ_purchases = purchases_network(purchase_input)    #G\n",
        "    in_game_purchases = sample(\"In-game Purchases\", Normal(μ_purchases, σ_purchases))    #H\n",
        "\n",
        "#A The causal model.\n",
        "#B A latent variable that acts as a proxy for other confounders.\n",
        "#C Whether someone is in a guild.\n",
        "#D Use confounders_2_engagement map is_guild_member and z to a parameter for Side-quest Engagement and In-game Purchases.\n",
        "#E Modeling Side-quest Engagement\n",
        "#F Modeling amount of won items\n",
        "#G Use confounders_2_purchases to map is_guild_member, z, and won-items to in_game_purchases.\n",
        "#H Model in_game_purchases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJZwnGHprY10",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pyro\n",
        "from pyro import render_model, plate\n",
        "from pyro.distributions import Beta\n",
        "from pyro import render_model\n",
        "\n",
        "confounders_2_engagement = Confounders2Engagement().to(device)    #A\n",
        "purchases_network = PurchasesNetwork().to(device)    #A\n",
        "\n",
        "\n",
        "def data_model(data, device=device):\n",
        "    pyro.module(\"confounder_2_engagement\", confounders_2_engagement)    #B\n",
        "    pyro.module(\"confounder_2_purchases\", purchases_network)    #B\n",
        "    params = {\n",
        "        'ρ_member': sample('ρ_member', Beta(tensor(5., device=device), tensor(5., device=device))),    #C\n",
        "        'ρ_won_engaged': sample('ρ_won_engaged', Beta(tensor(5., device=device), tensor(2., device=device))),    #D\n",
        "        'ρ_won_not_engaged': sample('ρ_won_not_engaged', Beta(tensor(2., device=device), tensor(5., device=device))),    #E\n",
        "    }\n",
        "    N = len(data[\"In-game Purchases\"])\n",
        "    with plate(\"N\", N):    #F\n",
        "        model(params)    #F\n",
        "\n",
        "render_model(data_model, (data, ))\n",
        "\n",
        "#A Initialize the neural networks\n",
        "#B pyro.module lets Pyro know about all the parameters inside the networks\n",
        "#C Sample from prior distribution for ρ_member\n",
        "#E Sample prior distribution for ρ_won_not_engaged\n",
        "#F The plate context manager declares N independent samples (observations) from the causal variabeles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUtzf2aKrY11"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim=3, #A\n",
        "                 z_dim=1,    #B\n",
        "                 hidden_dim=5):    #C\n",
        "        super().__init__()\n",
        "        self.f_hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.f_loc = nn.Linear(hidden_dim, z_dim)\n",
        "        self.f_scale = nn.Linear(hidden_dim, z_dim)\n",
        "        self.softplus = nn.Softplus()\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.t()\n",
        "        hidden = self.softplus(self.f_hidden(input))    #D\n",
        "        z_loc = self.f_loc(hidden)   #E\n",
        "        z_scale = 1e-6 + self.softplus(self.f_scale(hidden))    #F\n",
        "        return z_loc.t().squeeze(0), z_scale.t().squeeze(0)\n",
        "\n",
        "#A Input dimension is 3 because it will combine Side-quest Engagement, In-Game Purchases, and Guild Membership.\n",
        "#B I use a simple univarite Z, but one could give it higher dimension with sufficient data.\n",
        "#C The width of the hidden layer is 5.\n",
        "#D Go from input to hidden layer.\n",
        "#E Mapping from hidden layer to location parameter for Z.\n",
        "#F Mapping from hidden layer scale parameter to Z."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TarNpzdrY11"
      },
      "outputs": [],
      "source": [
        "from pyro import param\n",
        "from torch.distributions.constraints import positive\n",
        "\n",
        "encoder = Encoder().to(device)\n",
        "\n",
        "def guide(data, device=device):\n",
        "    pyro.module(\"encoder\", encoder)\n",
        "    α_member = param(\"α_member\", tensor(1.0, device=device),    #A\n",
        "                     constraint=positive)    #A\n",
        "    β_member = param(\"β_member\", tensor(1.0, device=device),    #A\n",
        "                        constraint=positive)    #A\n",
        "    sample('ρ_member', Beta(α_member, β_member))    #A\n",
        "    α_won_engaged = param(\"α_won_engaged\", tensor(5.0, device=device),    #B\n",
        "                         constraint=positive)    #B\n",
        "    β_won_engaged = param(\"β_won_engaged\", tensor(2.0, device=device),    #B\n",
        "                        constraint=positive)    #B\n",
        "    sample('ρ_won_engaged', Beta(α_won_engaged, β_won_engaged))    #B\n",
        "    α_won_not_engaged = param(\"α_won_not_engaged\", tensor(2.0, device=device),    #B\n",
        "                         constraint=positive)    #B\n",
        "    β_won_not_engaged = param(\"β_won_not_engaged\", tensor(5.0, device=device),    #B\n",
        "                        constraint=positive)    #B\n",
        "    sample('ρ_won_not_engaged', Beta(α_won_not_engaged, β_won_not_engaged))    #B\n",
        "    N = len(data[\"In-game Purchases\"])\n",
        "    with pyro.plate(\"N\", N):\n",
        "        z_input = torch.stack(    #C\n",
        "            (data[\"Guild Membership\"],    #C\n",
        "             data[\"Side-quest Engagement\"],    #C\n",
        "             data[\"In-game Purchases\"])    #C\n",
        "        ).to(device)    #C\n",
        "        z_loc, z_scale = encoder(z_input)    #C\n",
        "        pyro.sample(\"Z\", Normal(z_loc, z_scale))    #C\n",
        "\n",
        "\n",
        "#A The guide samples ρ_member from a Beta distribution where the shape parameters are trainable.\n",
        "#B ρ_won_engaged and p_won_not_engaged are also sampled from Beta distributions with trainable parameters.\n",
        "#C Z is sampled from a Normal with parameters returned by the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtPeiKSKrY11"
      },
      "outputs": [],
      "source": [
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "from pyro import condition\n",
        "\n",
        "pyro.clear_param_store()    #A\n",
        "adam_params = {\"lr\": 0.0001, \"betas\": (0.90, 0.999)}    #B\n",
        "optimizer = Adam(adam_params)    #B\n",
        "training_model = condition(data_model, data)    #C\n",
        "svi = SVI(training_model, guide, optimizer, loss=Trace_ELBO())    #D\n",
        "elbo_values = []    #E\n",
        "N = len(data['In-game Purchases'])    #E\n",
        "for step in range(500000):    #E\n",
        "    loss = svi.step(data) / N    #E\n",
        "    elbo_values.append(loss)   #E\n",
        "    if step % 500 == 0:    #E\n",
        "        print(loss)    #E\n",
        "#A Erase parameter values in case you restart the training loop.\n",
        "#B Setup Adam optimizer. A learning rate (\"lr\") of 0.001 may work better if using CUDA.\n",
        "#C Condition the data_model on the observed data\n",
        "#D Setup SVI.\n",
        "#E Run the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1X8B5K3rY11"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([math.log(item) for item in elbo_values])    #A\n",
        "plt.xlabel('Step')    #A\n",
        "plt.ylabel('Log-Loss')    #A\n",
        "plt.title('Training Loss')    #A\n",
        "plt.show()    #A\n",
        "#A Plot the log of training loss since loss is initially large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoHzngHarY12"
      },
      "outputs": [],
      "source": [
        " pyro.param(\"α_member\"), pyro.param(\"β_member\"), pyro.param(\"α_won_engaged\"), pyro.param(\"β_won_engaged\"), pyro.param(\"α_won_not_engaged\"), pyro.param(\"β_won_not_engaged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1rJAIOhrY12"
      },
      "outputs": [],
      "source": [
        "#!pip install seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyro.infer import Predictive\n",
        "\n",
        "predictive = Predictive(data_model, guide=guide, num_samples=1000)    #A\n",
        "predictive_samples = predictive(data)    #A\n",
        "\n",
        "for i, sample_data in enumerate(predictive_samples[\"In-game Purchases\"]):    #B\n",
        "    if i == 0:    #B\n",
        "        sns.kdeplot(sample_data, color=\"lightgrey\", label=\"Predictive density\")    #B\n",
        "    else:    #B\n",
        "        sns.kdeplot(sample_data, color=\"lightgrey\", linewidth=0.2, alpha=0.5)    #B\n",
        "\n",
        "sns.kdeplot(    #C\n",
        "    data['In-game Purchases'],    #C\n",
        "    color=\"black\",    #C\n",
        "    linewidth=1,    #C\n",
        "    label=\"Empirical density\"    #C\n",
        ")    #C\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Posterior Predictive Check of In-game Purchases\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOnw5Ve7rY12"
      },
      "outputs": [],
      "source": [
        "from pyro import do\n",
        "\n",
        "data_model_high_engagement = do(data_model, {\"Side-quest Engagement\": 1.})    #A\n",
        "predictive_high_engagement = Predictive(data_model_high_engagement, guide=guide, num_samples=1000)    #B\n",
        "predictive_high_engagement_samples = predictive_high_engagement(data)    #B\n",
        "\n",
        "for i, sample_data in enumerate(predictive_high_engagement_samples[\"In-game Purchases\"]):    #C\n",
        "    sns.kdeplot(sample_data, color=\"lightgrey\", linewidth=0.2, alpha=0.5)    #C\n",
        "plt.legend()    #C\n",
        "plt.title(\"Posterior predictive samples of $P(I_{E=1})$'s density curves\")    #C\n",
        "plt.xlabel(\"Value\")    #C\n",
        "plt.ylabel(\"Density\")    #C\n",
        "plt.show()    #C\n",
        "\n",
        "#A Use's numpyro's \"do\" intervention operation to transform the modeled.\n",
        "#B Forward generate samples from the transformed model conditional on the samples from the posterior. Simple forward generation is all we need in this case. A conditional query (P(IE=1|E=0)) would require a more general inference algorithm.\n",
        "#C Plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJwpozlwrY12"
      },
      "outputs": [],
      "source": [
        "expectation_high_engagement = predictive_high_engagement_samples['In-game Purchases'].mean(1)    #A\n",
        "data_model_low_engagement = do(data_model, {\"Side-quest Engagement\": 0.})    #A\n",
        "predictive_low_engagement = Predictive(data_model_low_engagement, guide=guide, num_samples=1000)    #B\n",
        "predictive_low_engagement_samples = predictive_low_engagement(data)    #B\n",
        "expectation_low_engagement = predictive_low_engagement_samples['In-game Purchases'].mean(1)    #B\n",
        "ate_distribution = expectation_high_engagement - expectation_low_engagement    #C\n",
        "\n",
        "sns.kdeplot(ate_distribution)    #D\n",
        "plt.title(\"Posterior distribution of the ATE\")    #D\n",
        "plt.xlabel(\"Value\")    #D\n",
        "plt.ylabel(\"Density\")    #D\n",
        "plt.show()    #D\n",
        "\n",
        "#A Estimate posterior predictive distribution of E(Y_E=1).\n",
        "#B Estimate posterior predictive distribution of  E(Y_E=0).\n",
        "#C Calculate  posterior predictive distribution of ATE = E(Y_E=1) - E(Y_E=0)\n",
        "#D Plot the results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}