{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74-7IkZ5eNRd",
        "outputId": "6727799a-4d0f-4bba-d753-a7a6d5a7c94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.10/dist-packages (0.1.24)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.0+cu118)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.3.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgraphviz-dev is already the newest version (2.42.2-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Requirement already satisfied: pygraphviz in /usr/local/lib/python3.10/dist-packages (1.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install pgmpy\n",
        "!pip install graphviz    #A\n",
        "!apt install libgraphviz-dev    #A\n",
        "!pip install pygraphviz    #A\n",
        "\n",
        "import graphviz    #A\n",
        "def plot_graph(G):    #A\n",
        "    write_dot(G, 'graph.dot')    #A\n",
        "    with open('graph.dot') as f:    #A\n",
        "        dot_graph = f.read()    #A\n",
        "    return graphviz.Source(dot_graph)    #A\n",
        "\n",
        "\n",
        "import requests\n",
        "url1 = \"https://raw.githubusercontent.com/altdeep/causalML/master/book/pgmpy_do.py\"     #B\n",
        "response1 = requests.get(url1)     #B\n",
        "exec(response1.text)     #B\n",
        "url2 = \"https://raw.githubusercontent.com/altdeep/causalML/master/book/chapter%209/hyp_function.py\"     #C\n",
        "response2 = requests.get(url2)     #C\n",
        "exec(response2.text)     #C\n",
        "\n",
        "#A Install raphviz for visualization and create a graphviz helper function. Graphviz installation may vary across environments.\n",
        "#B Import a function for an ideal intervention.\n",
        "#C Import a helper function for cloning assignment functions across worlds."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by revisiting the SCM for the Monte Hall problem. Summarizing again, there is a game show where the player starts with a choice of three doors. Behind one door is a car. The player picks a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which does not have the car. The host gives the player the opportunity to switch doors.  In this case since the player picked No. 1 and the host revealed the car is not behind door No. 3, the player can switch to door No. 2. The question is whether a strategy of staying with the original choice or switching doors is better. The answer is, counterintuitively to many, that a switching strategy is better -- two times out of three, the switching strategy leads to a win.\n",
        "\n",
        "We'll modify this game to have random inputs to the system that will behave as endogenous variables with prior distributions.  Specifically, we'll introduce two rolls of three-sided dice and a coin flip.\n",
        "\n",
        "We'll call the first die roll \"Car Door Die Roll\", it selects a door for placement of the car.  The player rolls the second die, a variable we'll call \"1st Choice Die Roll\", to select the player's first door selection.  Both dice rolls assign a 1/3 probability to each outcome.\n",
        "\n",
        "Next we have a coin flip, which will drive two outcomes.  Firstly, the host will use the outcome of the coin flip to select which door to open.  If the player selects the door with the car, when the host goes to reveal a carless door to the player, the host has two carless doors to choose from.  In this case, the host selects the right-most available door if he flips a heads, the left-most if he flips a tails.\n",
        "Similarly, we'll assume the player leaves their decision of whether to switch doors or to stay with the original choice up to the coin flip as well.  If the coin flips heads, they switch, otherwise they stay."
      ],
      "metadata": {
        "id": "rg0mr6GnUWTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from networkx.drawing.nx_agraph import write_dot\n",
        "from pgmpy.factors.discrete.CPD import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "from pgmpy.models import BayesianNetwork\n",
        "\n",
        "\n",
        "p_door_with_car = TabularCPD(    #A\n",
        "    variable='Car Door Die Roll',    #A\n",
        "    variable_card=3,    #A\n",
        "    values=[[1/3], [1/3], [1/3]],    #A\n",
        "    state_names={'Car Door Die Roll': ['1st', '2nd', '3rd']}    #A\n",
        ")    #A\n",
        "\n",
        "p_player_first_choice = TabularCPD(    #B\n",
        "    variable='1st Choice Die Roll',    #B\n",
        "    variable_card=3,    #B\n",
        "    values=[[1/3], [1/3], [1/3]],    #B\n",
        "    state_names={'1st Choice Die Roll': ['1st', '2nd', '3rd']}    #B\n",
        ")    #B\n",
        "\n",
        "p_coin_flip = TabularCPD(       #C\n",
        "    variable='Coin Flip',    #C\n",
        "    variable_card=2,    #C\n",
        "    values=[[.5], [.5]],    #C\n",
        "    state_names={'Coin Flip': ['tails', 'heads']}    #C\n",
        ")    #C\n",
        "\n",
        "#A Prior distribution on exogenous variable for the three-sided die roll that selects which door gets the car.\n",
        "#B Prior distribution on the exogenous variable for the three-sided die roll that selects the player's first choice of door.\n",
        "#C Prior distribution on the exogenous variable for the coin flip.  The host flips a coin. The coin flip impacts which door the host chooses to reveal as carless, and whether the player chooses a stay or switch strategy."
      ],
      "metadata": {
        "id": "HccOxMc8gtSJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_strategy = TabularCPD(    #A\n",
        "    variable='Strategy',    #A\n",
        "    variable_card=2,    #A\n",
        "    values=[[1, 0], [0, 1]],    #A\n",
        "    evidence=['Coin Flip'],    #A\n",
        "    evidence_card=[2],    #A\n",
        "    state_names={    #A\n",
        "        'Strategy': ['stay', 'switch'],    #A\n",
        "        'Coin Flip': ['tails', 'heads']}    #A\n",
        ")    #A\n",
        "\n",
        "f_host_door_selection = TabularCPD(    #B\n",
        "    variable='Host Door Selection',    #B\n",
        "    variable_card=3,    #B\n",
        "    values=[    #B\n",
        "        [0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,1,0],    #B\n",
        "        [1,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1],    #B\n",
        "        [0,1,0,1,0,0,0,0,0,1,1,0,1,1,0,0,0,0]    #B\n",
        "    ],    #B\n",
        "    evidence=['Coin Flip', 'Car Door Die Roll', '1st Choice Die Roll'],    #B\n",
        "    evidence_card=[2, 3, 3],    #B\n",
        "    state_names={    #B\n",
        "        'Host Door Selection':['1st', '2nd', '3rd'],    #B\n",
        "        'Coin Flip': ['tails', 'heads'],    #B\n",
        "        'Car Door Die Roll': ['1st', '2nd', '3rd'],    #B\n",
        "        '1st Choice Die Roll': ['1st', '2nd', '3rd']    #B\n",
        "    }    #B\n",
        ")    #B\n",
        "\n",
        "f_second_choice = TabularCPD(    #C\n",
        "    variable='2nd Choice',    #C\n",
        "    variable_card=3,    #C\n",
        "    values=[    #C\n",
        "        [1,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,1,0],    #C\n",
        "        [0,1,0,0,1,0,0,1,0,1,0,1,0,1,0,1,0,1],    #C\n",
        "        [0,0,1,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0]    #C\n",
        "    ],    #C\n",
        "    evidence=['Strategy', 'Host Door Selection', '1st Choice Die Roll'],    #C\n",
        "    evidence_card=[2, 3, 3],    #C\n",
        "    state_names={    #C\n",
        "        '2nd Choice': ['1st', '2nd', '3rd'],    #C\n",
        "        'Strategy': ['stay', 'switch'],    #C\n",
        "        'Host Door Selection': ['1st', '2nd', '3rd'],    #C\n",
        "        '1st Choice Die Roll': ['1st', '2nd', '3rd']    #C\n",
        "    }    #C\n",
        ")    #C\n",
        "\n",
        "f_win_or_lose = TabularCPD(    #D\n",
        "    variable='Win or Lose',    #D\n",
        "    variable_card=2,    #D\n",
        "    values=[    #D\n",
        "        [1,0,0,0,1,0,0,0,1],    #D\n",
        "        [0,1,1,1,0,1,1,1,0],    #D\n",
        "    ],    #D\n",
        "    evidence=['2nd Choice', 'Car Door Die Roll'],    #D\n",
        "    evidence_card=[3, 3],    #D\n",
        "    state_names={    #D\n",
        "        'Win or Lose': ['win', 'lose'],    #D\n",
        "        '2nd Choice': ['1st', '2nd', '3rd'],    #D\n",
        "        'Car Door Die Roll': ['1st', '2nd', '3rd']    #D\n",
        "    }    #D\n",
        ")    #D\n",
        "#A If the outcome of the coin flip was a heads, the player switches doors from their initial selection. Otherwise, they stay.\n",
        "#B Host selects the door to reveal as carless based on the player's choice of door and the door with the car.  If those are the same door, the host has two doors to chose from.  If this case, if the coin fipped tails, the host chooses the left-most door, otherwise the right-most door.\n",
        "#C The player chooses which door to select in the second round based on the choice in the first round (outcome of 1st Choice Die Roll), the door opened by the host, and whether the player's coin flip told them to stay or switch doors from their initial selection.\n",
        "#D The player wins or loses based on their choice of door in the second round and the door with the car.\n"
      ],
      "metadata": {
        "id": "uMwRBO9r26Ye"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exogenous_vars = [\"Car Door Die Roll\", \"Coin Flip\", \"1st Choice Die Roll\"]    #A\n",
        "endogenous_vars = [\"Host Door Selection\", \"Strategy\", \"2nd Choice\", \"Win or Lose\"]    #A\n",
        "\n",
        "actual_world_edges = [    #B\n",
        "    ('Coin Flip', 'Host Door Selection'),    #B\n",
        "    ('Coin Flip', 'Strategy'),    #B\n",
        "    ('Car Door Die Roll', 'Host Door Selection'),    #B\n",
        "    ('1st Choice Die Roll', 'Host Door Selection'),    #B\n",
        "    ('1st Choice Die Roll', '2nd Choice'),    #B\n",
        "    ('Host Door Selection', '2nd Choice'),    #B\n",
        "    ('Strategy', '2nd Choice'),    #B\n",
        "    ('2nd Choice', 'Win or Lose'),    #B\n",
        "    ('Car Door Die Roll', 'Win or Lose')    #B\n",
        "]    #B\n",
        "\n",
        "possible_world_edges = [    #C\n",
        "    (a + \" Hyp\" if a in endogenous_vars else a,    #C\n",
        "     b + \" Hyp\" if b in endogenous_vars else b)    #C\n",
        "    for a, b in actual_world_edges    #C\n",
        "]    #C\n",
        "\n",
        "twin_world_graph = BayesianNetwork(    #D\n",
        "    actual_world_edges +    #D\n",
        "    possible_world_edges    #D\n",
        ")    #D\n",
        "\n",
        "twin_world_graph.add_cpds(    #E\n",
        "    p_door_with_car,    #F\n",
        "    p_player_first_choice,    #F\n",
        "    p_coin_flip,    #F\n",
        "    f_strategy,    #G\n",
        "    f_host_door_selection,    #G\n",
        "    f_second_choice,    #G\n",
        "    f_win_or_lose,    #G\n",
        "    clone(f_strategy),    #H\n",
        "    clone(f_host_door_selection),    #H\n",
        "    clone(f_second_choice),    #H\n",
        "    clone(f_win_or_lose),    #H\n",
        ")\n",
        "\n",
        "plot_graph(twin_world_graph)\n",
        "\n",
        "#A Specify lists of the exogenous and endogenous variables in the causal DAG.\n",
        "#B Specify the edges of the SCM\n",
        "#C Clone the edges for the hypothetical world\n",
        "#D Create parallel world graph\n",
        "#E Plot the parallel world graph\n",
        "#F Add probability distributions on exogenous variables.\n",
        "#G Add assignment functions from the SCM\n",
        "#H Clone assignment functions"
      ],
      "metadata": {
        "id": "dTG4rjEEuhDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "92ecc9a5-764b-468d-cf67-ed3874f3db3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"777pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 776.99 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 772.99,-256 772.99,4 -4,4\"/>\n<!-- Coin Flip -->\n<g id=\"node1\" class=\"node\">\n<title>Coin Flip</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"250.3\" cy=\"-234\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"250.3\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Coin Flip</text>\n</g>\n<!-- Host Door Selection -->\n<g id=\"node2\" class=\"node\">\n<title>Host Door Selection</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"315.3\" cy=\"-162\" rx=\"83.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"315.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Host Door Selection</text>\n</g>\n<!-- Coin Flip&#45;&gt;Host Door Selection -->\n<g id=\"edge1\" class=\"edge\">\n<title>Coin Flip&#45;&gt;Host Door Selection</title>\n<path fill=\"none\" stroke=\"black\" d=\"M265.37,-216.76C273.42,-208.1 283.49,-197.25 292.48,-187.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"295.16,-189.83 299.4,-180.12 290.03,-185.07 295.16,-189.83\"/>\n</g>\n<!-- Strategy -->\n<g id=\"node3\" class=\"node\">\n<title>Strategy</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"40.3\" cy=\"-162\" rx=\"40.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Strategy</text>\n</g>\n<!-- Coin Flip&#45;&gt;Strategy -->\n<g id=\"edge2\" class=\"edge\">\n<title>Coin Flip&#45;&gt;Strategy</title>\n<path fill=\"none\" stroke=\"black\" d=\"M216.63,-222.09C184.02,-211.48 133.2,-194.84 89.3,-180 86.54,-179.07 83.69,-178.1 80.83,-177.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"81.71,-173.72 71.11,-173.78 79.43,-180.34 81.71,-173.72\"/>\n</g>\n<!-- Host Door Selection Hyp -->\n<g id=\"node4\" class=\"node\">\n<title>Host Door Selection Hyp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"555.3\" cy=\"-162\" rx=\"100.98\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"555.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Host Door Selection Hyp</text>\n</g>\n<!-- Coin Flip&#45;&gt;Host Door Selection Hyp -->\n<g id=\"edge3\" class=\"edge\">\n<title>Coin Flip&#45;&gt;Host Door Selection Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M288,-224.35C337.29,-213.03 424.57,-193 485.95,-178.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"486.99,-182.27 495.95,-176.62 485.42,-175.45 486.99,-182.27\"/>\n</g>\n<!-- Strategy Hyp -->\n<g id=\"node5\" class=\"node\">\n<title>Strategy Hyp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"156.3\" cy=\"-162\" rx=\"57.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"156.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Strategy Hyp</text>\n</g>\n<!-- Coin Flip&#45;&gt;Strategy Hyp -->\n<g id=\"edge4\" class=\"edge\">\n<title>Coin Flip&#45;&gt;Strategy Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M229.9,-217.81C216.99,-208.2 200.09,-195.61 185.74,-184.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.74,-182.05 177.63,-178.89 183.56,-187.67 187.74,-182.05\"/>\n</g>\n<!-- 2nd Choice -->\n<g id=\"node6\" class=\"node\">\n<title>2nd Choice</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"396.3\" cy=\"-90\" rx=\"51.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"396.3\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">2nd Choice</text>\n</g>\n<!-- Host Door Selection&#45;&gt;2nd Choice -->\n<g id=\"edge5\" class=\"edge\">\n<title>Host Door Selection&#45;&gt;2nd Choice</title>\n<path fill=\"none\" stroke=\"black\" d=\"M334.49,-144.41C345.14,-135.21 358.52,-123.64 370.11,-113.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"372.52,-116.17 377.8,-106.99 367.94,-110.88 372.52,-116.17\"/>\n</g>\n<!-- Strategy&#45;&gt;2nd Choice -->\n<g id=\"edge6\" class=\"edge\">\n<title>Strategy&#45;&gt;2nd Choice</title>\n<path fill=\"none\" stroke=\"black\" d=\"M70.12,-149.79C76.4,-147.67 83.02,-145.62 89.3,-144 174.88,-121.92 276.28,-106.44 338.45,-98.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"339,-101.58 348.45,-96.8 338.08,-94.64 339,-101.58\"/>\n</g>\n<!-- 2nd Choice Hyp -->\n<g id=\"node11\" class=\"node\">\n<title>2nd Choice Hyp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"585.3\" cy=\"-90\" rx=\"68.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"585.3\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">2nd Choice Hyp</text>\n</g>\n<!-- Host Door Selection Hyp&#45;&gt;2nd Choice Hyp -->\n<g id=\"edge16\" class=\"edge\">\n<title>Host Door Selection Hyp&#45;&gt;2nd Choice Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M562.71,-143.7C566.09,-135.81 570.17,-126.3 573.92,-117.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"577.24,-118.67 577.97,-108.1 570.81,-115.92 577.24,-118.67\"/>\n</g>\n<!-- Strategy Hyp&#45;&gt;2nd Choice Hyp -->\n<g id=\"edge17\" class=\"edge\">\n<title>Strategy Hyp&#45;&gt;2nd Choice Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M198.68,-149.54C206.82,-147.54 215.29,-145.6 223.3,-144 277.73,-133.14 426.55,-112.41 515.52,-100.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"516.09,-103.8 525.53,-98.99 515.15,-96.86 516.09,-103.8\"/>\n</g>\n<!-- Win or Lose -->\n<g id=\"node8\" class=\"node\">\n<title>Win or Lose</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"494.3\" cy=\"-18\" rx=\"55.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"494.3\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Win or Lose</text>\n</g>\n<!-- 2nd Choice&#45;&gt;Win or Lose -->\n<g id=\"edge15\" class=\"edge\">\n<title>2nd Choice&#45;&gt;Win or Lose</title>\n<path fill=\"none\" stroke=\"black\" d=\"M418.05,-73.46C431.53,-63.84 449.04,-51.32 463.89,-40.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"466.17,-43.39 472.27,-34.73 462.1,-37.7 466.17,-43.39\"/>\n</g>\n<!-- Car Door Die Roll -->\n<g id=\"node7\" class=\"node\">\n<title>Car Door Die Roll</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"692.3\" cy=\"-234\" rx=\"76.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"692.3\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">Car Door Die Roll</text>\n</g>\n<!-- Car Door Die Roll&#45;&gt;Host Door Selection -->\n<g id=\"edge7\" class=\"edge\">\n<title>Car Door Die Roll&#45;&gt;Host Door Selection</title>\n<path fill=\"none\" stroke=\"black\" d=\"M634.22,-222.22C567.44,-209.82 457.84,-189.47 386.12,-176.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"386.73,-172.7 376.26,-174.32 385.45,-179.59 386.73,-172.7\"/>\n</g>\n<!-- Car Door Die Roll&#45;&gt;Host Door Selection Hyp -->\n<g id=\"edge9\" class=\"edge\">\n<title>Car Door Die Roll&#45;&gt;Host Door Selection Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M661.89,-217.46C642.53,-207.57 617.21,-194.63 596.1,-183.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"597.54,-180.65 587.04,-179.22 594.36,-186.89 597.54,-180.65\"/>\n</g>\n<!-- Car Door Die Roll&#45;&gt;Win or Lose -->\n<g id=\"edge8\" class=\"edge\">\n<title>Car Door Die Roll&#45;&gt;Win or Lose</title>\n<path fill=\"none\" stroke=\"black\" d=\"M694.74,-216C698.4,-183.39 701.25,-111.74 663.3,-72 636.04,-43.46 593.64,-30.22 558.13,-24.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"558.26,-20.58 547.84,-22.5 557.18,-27.5 558.26,-20.58\"/>\n</g>\n<!-- Win or Lose Hyp -->\n<g id=\"node9\" class=\"node\">\n<title>Win or Lose Hyp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"689.3\" cy=\"-18\" rx=\"72.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"689.3\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Win or Lose Hyp</text>\n</g>\n<!-- Car Door Die Roll&#45;&gt;Win or Lose Hyp -->\n<g id=\"edge10\" class=\"edge\">\n<title>Car Door Die Roll&#45;&gt;Win or Lose Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M711.31,-216.38C720.78,-206.82 731.26,-193.95 736.3,-180 752.59,-134.85 753.33,-116.88 736.3,-72 732.15,-61.08 724.62,-50.98 716.78,-42.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"719.12,-39.97 709.58,-35.37 714.17,-44.92 719.12,-39.97\"/>\n</g>\n<!-- 1st Choice Die Roll -->\n<g id=\"node10\" class=\"node\">\n<title>1st Choice Die Roll</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"456.3\" cy=\"-234\" rx=\"81.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"456.3\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">1st Choice Die Roll</text>\n</g>\n<!-- 1st Choice Die Roll&#45;&gt;Host Door Selection -->\n<g id=\"edge11\" class=\"edge\">\n<title>1st Choice Die Roll&#45;&gt;Host Door Selection</title>\n<path fill=\"none\" stroke=\"black\" d=\"M424.65,-217.29C404.33,-207.2 377.75,-194.01 355.89,-183.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"357.35,-179.97 346.83,-178.66 354.23,-186.24 357.35,-179.97\"/>\n</g>\n<!-- 1st Choice Die Roll&#45;&gt;Host Door Selection Hyp -->\n<g id=\"edge13\" class=\"edge\">\n<title>1st Choice Die Roll&#45;&gt;Host Door Selection Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M479.51,-216.59C492.57,-207.35 509.07,-195.68 523.34,-185.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"525.74,-188.18 531.89,-179.55 521.7,-182.47 525.74,-188.18\"/>\n</g>\n<!-- 1st Choice Die Roll&#45;&gt;2nd Choice -->\n<g id=\"edge12\" class=\"edge\">\n<title>1st Choice Die Roll&#45;&gt;2nd Choice</title>\n<path fill=\"none\" stroke=\"black\" d=\"M449.06,-215.87C438.74,-191.46 419.72,-146.43 407.55,-117.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"410.68,-116.04 403.56,-108.19 404.23,-118.76 410.68,-116.04\"/>\n</g>\n<!-- 1st Choice Die Roll&#45;&gt;2nd Choice Hyp -->\n<g id=\"edge14\" class=\"edge\">\n<title>1st Choice Die Roll&#45;&gt;2nd Choice Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M525.79,-224.58C579.72,-216.45 648.11,-202.08 665.3,-180 675.12,-167.37 672.87,-158.1 665.3,-144 657.67,-129.79 644.37,-118.75 630.78,-110.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"632.3,-107.35 621.87,-105.5 628.87,-113.45 632.3,-107.35\"/>\n</g>\n<!-- 2nd Choice Hyp&#45;&gt;Win or Lose Hyp -->\n<g id=\"edge18\" class=\"edge\">\n<title>2nd Choice Hyp&#45;&gt;Win or Lose Hyp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M609.16,-72.94C623.19,-63.49 641.14,-51.41 656.5,-41.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"658.85,-43.71 665.19,-35.23 654.94,-37.91 658.85,-43.71\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7b050a3543a0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates are SCM, which we can use to generate samples."
      ],
      "metadata": {
        "id": "dwGK1vPVto2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check, we confirm the result that the probability of winning is 2/3 if the player uses the switch strategy.\n"
      ],
      "metadata": {
        "id": "H2xJfbYYvm-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer = VariableElimination(twin_world_graph)\n",
        "\n",
        "strategy_outcome = infer.query(\n",
        "    ['Win or Lose'],\n",
        "    evidence={\"Strategy\": \"switch\"}\n",
        ")\n",
        "print(strategy_outcome)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmj11A6Qvsyt",
        "outputId": "bca55fb6-9fcc-4e60-ef4a-62f89fb9150d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+\n",
            "| Win or Lose       |   phi(Win or Lose) |\n",
            "+===================+====================+\n",
            "| Win or Lose(win)  |             0.6667 |\n",
            "+-------------------+--------------------+\n",
            "| Win or Lose(lose) |             0.3333 |\n",
            "+-------------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we explore how to run the counterfactual inference algorithm using this SCM.  Firstly, we need to apply an ideal intervention to implement the hypothetical condition of using the \"switch\" strategy.  The \"do\"-method of the BayesianNetwork object applies graph surgery.  To implement a full ideal intervention, we need to augment the method so that it additionally modifies the distribution to put all the probability on the intervention value."
      ],
      "metadata": {
        "id": "sB3bpvQv5nNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll explore two counterfactual questions:\n",
        "\n",
        "\n",
        "\n",
        "1.   For a player who stayed with their first door and lost, what is the probability that they would have won if they switched doors?\n",
        "2.   For a player who lost, what is the probability they would have won if they switched doors?\n",
        "\n",
        "In the *abduction step* of the counterfactual inference algorithm, we infer the exogenous variables given the actual conditions.  Let's confirm that we can infer"
      ],
      "metadata": {
        "id": "vyaZAOfZ8acD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, with the variable elimination inference algorithm, we need not do infer the exogenous variables directly.  Rather, we can implement a parallel world graph directly.  Then, when we condition on actual variables, the variable elimination algorithm will \"eliminate\" (meaning \"sum over\") all the exogenous variables (and any other latent variables) as it calculates the probabilities of outcomes for the hypothetical outcomes of interest.\n",
        "\n",
        "Let's start by creating assignment functions for variables in the hypothetical world.  These will be the same as the original assignment functions, except we'll modify the names with \"Hyp\" to index the hypothetical world."
      ],
      "metadata": {
        "id": "_x_DULVL87VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we use inference to answer the counterfactual questions.  Again, we use variable elimination as our choice of inference algorithm.\n",
        "\n"
      ],
      "metadata": {
        "id": "VnHLutJ5BWYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer = VariableElimination(twin_world_graph)    #A\n",
        "\n",
        "cf_dist1 = infer.query(    #B\n",
        "    ['Win or Lose Hyp'],    #B\n",
        "    evidence={'Strategy': 'stay', 'Win or Lose': 'lose'}    #B\n",
        ")    #B\n",
        "print(cf_dist1)\n",
        "\n",
        "cf_dist2 = infer.query(    #C\n",
        "    ['Win or Lose Hyp'],    #C\n",
        "    evidence={'Win or Lose': 'lose'}    #C\n",
        ")    #C\n",
        "print(cf_dist2)\n",
        "\n",
        "#A We apply variable elimination as our inference algorithm on the parallel world graph.\n",
        "#B The inference query that answers \"For a player who used the \"stay\" strategy and lost, would they have won if they used the \"switch\" strategy.  Conditional on Strategy == stay and 'Win or Lose' == lose, we infer the probability distribution of 'Win or Lose Hyp' on the parallel world graph.\n",
        "#C The inference query that answers \"For a player who lost, would they have won if they used the \"switch\" strategy.  Conditional on 'Win or Lose' == lose, we infer the probability distribution of 'Win or Lose Hyp' on the parallel world graph."
      ],
      "metadata": {
        "id": "BgzocHMclW-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37961471-eef3-4a4c-a562-1eb7eb7c220d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+------------------------+\n",
            "| Win or Lose Hyp       |   phi(Win or Lose Hyp) |\n",
            "+=======================+========================+\n",
            "| Win or Lose Hyp(win)  |                 0.0000 |\n",
            "+-----------------------+------------------------+\n",
            "| Win or Lose Hyp(lose) |                 1.0000 |\n",
            "+-----------------------+------------------------+\n",
            "+-----------------------+------------------------+\n",
            "| Win or Lose Hyp       |   phi(Win or Lose Hyp) |\n",
            "+=======================+========================+\n",
            "| Win or Lose Hyp(win)  |                 0.0000 |\n",
            "+-----------------------+------------------------+\n",
            "| Win or Lose Hyp(lose) |                 1.0000 |\n",
            "+-----------------------+------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can validate these answers with a bit of simple reasoning.\n",
        "\n",
        "The answer to the first question is perhaps obvious.  If the player lost on a \"stay\" strategy, then the their first choice did not have the car.  Then one of the other two doors must have had the car.  Of those two, the host would have had to open the one without the car.  The remain door has the car, and that is the only door the player can switch to on a switch strategy.  So, conditional on having lost with a stay strategy, the chances they would have won with a switch strategy are 100%.\n",
        "\n",
        "The answer to the second question extends from the first.  If we know a player lost but didn't know which strategy they used, then there is a 2/3 chance it was a stay strategy.  As we saw from the first question, in this case flipping to a \"switch\" has 100% chance of winning.  There is a 1/3 chance it was a switch strategy, in which case, by the consistency rule, there is 100% chance of losing."
      ],
      "metadata": {
        "id": "VsS3eXu6GLz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyro-ppl"
      ],
      "metadata": {
        "id": "AFF9m_3Tsgcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dab5661-a592-4b44-d45c-5821b70152f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.8.6-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.8/732.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pyro-ppl) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pyro-ppl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pyro-ppl) (1.3.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the forensic SCM relating femur length to human height.  Here, we modify the model by adding for biological sex, which drives both femur length and height.\n",
        "\n",
        "![forensic DAG](https://i.imgur.com/RTxf20m.png)"
      ],
      "metadata": {
        "id": "88VJ2A_3UGYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyro-ppl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import torch.distributions.constraints as constraints\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Bernoulli, Delta, Normal\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro import sample\n",
        "from pyro.optim import Adam\n",
        "from pyro.primitives import param\n",
        "\n",
        "from functools import partial    #A\n",
        "PseudoDelta = partial(Normal, scale=.01)    #A\n",
        "\n",
        "def f_sex(N_sex):    #B\n",
        "    return sample(\"sex\", Bernoulli(N_sex))    #B\n",
        "\n",
        "def f_femur(sex, N_femur):    #C\n",
        "    if sex == tensor(1.0):    #C\n",
        "        μ = 43.7 + 2.3 * N_femur    #C\n",
        "    else:    #C\n",
        "        μ = 40.238 + 1.9 * N_femur    #C\n",
        "    return sample(\"femur\", PseudoDelta(μ))    #C\n",
        "\n",
        "def f_height(femur, sex, N_height):    #D\n",
        "    if sex == tensor(1.0):    #D\n",
        "        μ = 61.41 + 2.21 * femur + 7.62 * N_height    #D\n",
        "    else:    #D\n",
        "        μ = 54.1 + 2.47 * femur + 7 * N_height    #D\n",
        "    return sample(\"height\", PseudoDelta(μ))    #D\n",
        "\n",
        "def model(exogenous):\n",
        "    N_sex = sample(\"N_sex\", exogenous['N_sex'])    #E\n",
        "    N_femur = sample(\"N_femur\", exogenous['N_femur'])    #E\n",
        "    N_height = sample(\"N_height\", exogenous['N_height'])    #E\n",
        "\n",
        "    sex = f_sex(N_sex)    #F\n",
        "    femur = f_femur(sex, N_femur)    #F\n",
        "    height = f_height(femur, sex, N_height)    #F\n",
        "    return sex, femur, height\n",
        "\n",
        "exogenous = {    #G\n",
        "    'N_sex': Bernoulli(.5),    #G\n",
        "    'N_femur': Normal(0., 1.),    #G\n",
        "    'N_height': Normal(0., 1.),    #G\n",
        "}    #G\n",
        "\n",
        "#A Endogenous variables are deterministic functions of the exogenous variables. But for variational inference to work, we need to assign the endogenous variables a distribution using pyro.sample. We could use the Dirac delta distribution, which would assign all probability value to the output of a variable's assignment function. But gradient-based optimization won't work in this case. So instead, we do approximate inference with a \"pseudo-delta\" distribution, which is a Normal distribution with a very small scale parameter.\n",
        "#B The assignment function for biological sex.\n",
        "#C The assignment function for femur length in cm. Assignment is comprised of two linear functions, one for each sex.\n",
        "#D  The assignment function for height.  Again, it is comprised of two linear functions, one for each sex.\n",
        "#E Sample from the exogenous variable prior distributions.\n",
        "#F Obtain the endogenous variables given the exogenous variables.\n",
        "#G Specify the prior distributions for the exogenous variables."
      ],
      "metadata": {
        "id": "dpmFjxzzsB6h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's pose the conditional hypothetical \"what would height be if femur length was 46cm?\"\n",
        "\n",
        "![int_dag](https://i.imgur.com/5zG2fTn.png)"
      ],
      "metadata": {
        "id": "BEI5lk9oTjVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_model = pyro.do(model, data={\"femur\": tensor(46.0)})    #A\n",
        "\n",
        "int_samples = []    #B\n",
        "for _ in range(10000):    #B\n",
        "    _, _, int_height = int_model(exogenous)    #B\n",
        "    int_samples.append(float(int_height))    #B\n",
        "\n",
        "plt.hist(    #C\n",
        "    int_samples,    #C\n",
        "    bins=20,    #C\n",
        "    alpha=0.5,    #C\n",
        "    label=\"Intervention Samples\",    #C\n",
        "    density=True    #C\n",
        ")\n",
        "plt.ylim(0., .35)    #C\n",
        "plt.legend()    #C\n",
        "plt.xlabel(\"Height\")    #C\n",
        "plt.show()    #C\n",
        "\n",
        "#A Implement the hypothetical condition \"...if femur length were 46cm\" with pyro.do, which returns a new model that implements the intervention.\n",
        "#B Sample from the intervention distribution.\n",
        "#C Visualize the intervention distribution with a histogram of samples."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Wmtbqf_bAElZ",
        "outputId": "b463416b-fcaf-48af-943d-1cbafab62e32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compare this to the counterfactual \"An individual's femur is 44cm and their height is 165cm.  What would the height be if femur length was 46cm?\"\n",
        "\n",
        "![cf distribution](https://i.imgur.com/5KaSxnw.png)"
      ],
      "metadata": {
        "id": "ejVdSm7BvTUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditioned_model = pyro.condition(    #A\n",
        "    model,    #A\n",
        "    data={\"femur\": tensor(44.0), \"height\": tensor(165.0)}    #A\n",
        ")    #A\n",
        "\n",
        "def guide(exogenous):    #B\n",
        "    p = param(\"p\", tensor(.5), constraint=constraints.unit_interval)    #C\n",
        "    n_sex = sample(\"N_sex\", Bernoulli(p))    #C\n",
        "    sex = sample(\"sex\", Bernoulli(n_sex))    #D\n",
        "    n_femur_loc = param(\"n_femur_loc\", tensor(0.0))    #E\n",
        "    n_femur_scale = param(    #E\n",
        "        \"n_femur_scale\",    #E\n",
        "        tensor(1.0),    #E\n",
        "        constraint=constraints.positive    #E\n",
        "    )    #E\n",
        "    n_femur = sample(\"N_femur\", Normal(n_femur_loc, n_femur_scale))    #F\n",
        "    n_height_loc = param(\"n_height_loc\", tensor(0.0))    #F\n",
        "    n_height_scale = param(    #F\n",
        "        \"n_height_scale\",    #F\n",
        "        tensor(1.0),    #F\n",
        "        constraint=constraints.positive    #F\n",
        "    )    #F\n",
        "    n_height = sample(\"N_height\", Normal(n_height_loc, n_height_scale))    #F\n",
        "    femur = sample(\"femur\", Delta(n_femur))    #G\n",
        "    height = sample(\"height\", Delta(n_height))    #G\n",
        "\n",
        "pyro.util.set_rng_seed(123)    #H\n",
        "pyro.clear_param_store()    #I\n",
        "svi = SVI(    #J\n",
        "          model=conditioned_model,\n",
        "          guide=guide,\n",
        "          optim=Adam({\"lr\": 0.003}),    #K\n",
        "          loss=Trace_ELBO()    #L\n",
        ")\n",
        "\n",
        "losses = []    #M\n",
        "num_steps = 5000    #N\n",
        "for t in range(num_steps):    #N\n",
        "    losses.append(svi.step(exogenous))    #N\n",
        "\n",
        "plt.plot(losses)    #O\n",
        "plt.title(\"Loss During Training\")    #O\n",
        "plt.xlabel(\"step\")    #O\n",
        "plt.ylabel(\"loss\")    #O\n",
        "\n",
        "n_sex_p = param(\"p\").item()    #P\n",
        "n_femur_loc = param(\"n_femur_loc\").item()    #P\n",
        "n_femur_scale = param(\"n_femur_scale\").item()    #P\n",
        "n_height_loc = param(\"n_height_loc\").item()    #P\n",
        "n_height_scale = param(\"n_height_scale\").item()    #P\n",
        "\n",
        "exogenous_posterior = {    #Q\n",
        "    'N_sex': Bernoulli(n_sex_p),    #Q\n",
        "    'N_femur': Normal(n_femur_loc, n_femur_scale),    #Q\n",
        "    'N_height': Normal(n_height_loc, n_height_scale),    #Q\n",
        "}    #Q\n",
        "\n",
        "#A Condition on actual world outcomes of a 58cm femur and 160cm height.\n",
        "#B The exogenous prior distribution is passed to the guide function. The function won't use this argument, but the signatures of the guide and the model functions must match.\n",
        "#C The guide function tries to approximate P(N_sex|femur, height) from a Bernoulli distribution.  Optimization targets the parameter of this Bernoulli distribution.\n",
        "#D n_sex is either 0 or 1. When passed as a parameter to a Bernoulli, the outcome is deterministic.\n",
        "#E The guide function tries to approximate P(N_femur|femur, height) from a Normal distribution.  Optimization targets the location and scale parameters of this Normal distribution.\n",
        "#F The guide function tries to approximate P(N_height|femur, height) also from a Normal distribution.\n",
        "#G Since we condition on femur and height, they are not needed in the guide function. But it is useful to have them in case we want to condition on different outcomes.\n",
        "#H Set seed for reproducibility\n",
        "#I Clear any current parameter values\n",
        "#J Initialize the stochastic variational inference algorithm.\n",
        "#K Optimize the parameters with a learning rate of .003.\n",
        "#L Use evidence lower bound (ELBO) as the loss function.\n",
        "#M Initialize a list to store loss values for plotting.\n",
        "#N Run the optimization for 5000 steps.\n",
        "#O Plot the loss during training.\n",
        "#P Extract the parameter values.\n",
        "#Q Do the abduction step by using the optimized parameters to create a new exogenous variable distributions."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgTgW78HKEX-",
        "outputId": "d848a828-098f-41fd-d844-f89b24c9a6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyro/util.py:288: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n",
            "{'femur', 'height'}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pyro/util.py:288: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n",
            "{'femur', 'height'}\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, I forward simulate from the counterfactual distribution by passing the exogenous distributions into the intervened-upon model.\n",
        "\n",
        "![parallel world graph](https://i.imgur.com/5KaSxnw.png)"
      ],
      "metadata": {
        "id": "7NhfVAXz1aa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_samples = []    #A\n",
        "for _ in range(10000):    #A\n",
        "    _, _, cf_height = int_model(exogenous_posterior)    #A\n",
        "    cf_samples.append(float(cf_height))    #A\n",
        "\n",
        "plt.hist(    #B\n",
        "    int_samples,    #B\n",
        "    bins=20,    #B\n",
        "    alpha=0.5,    #B\n",
        "    label=\"Intervention Samples\",    #B\n",
        "    density=True    #B\n",
        ")\n",
        "plt.hist(    #B\n",
        "    cf_samples,    #B\n",
        "    bins=20,    #B\n",
        "    alpha=0.5,    #B\n",
        "    label=\"Counterfactual Samples\",    #B\n",
        "    density=True    #B\n",
        ")    #B\n",
        "plt.ylim(0., .35)\n",
        "plt.legend()    #B\n",
        "plt.xlabel(\"Height\")    #B\n",
        "plt.show()    #B\n",
        "\n",
        "#A Generate counterfactual samples by passing the posterior on noise variables to the intervention model.\n",
        "#B Overlay both the interventional and counterfactual histograms."
      ],
      "metadata": {
        "id": "xp97FPHIKX7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing flows example"
      ],
      "metadata": {
        "id": "qDGIGp12RrV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import pandas as pd\n",
        "from torch import tensor\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/altdeep/causalML/master/datasets/enzyme-data.csv\")   #A\n",
        "\n",
        "X = torch.tensor(df['x'].values).unsqueeze(1).float()    #B\n",
        "Y = torch.tensor(df['y'].values).unsqueeze(1).float()    #B\n",
        "\n",
        "\n",
        "from pyro.distributions import (\n",
        "    ConditionalTransformedDistribution,\n",
        "    Normal,\n",
        "    Uniform,\n",
        "    TransformedDistribution\n",
        ")\n",
        "from pyro.distributions.transforms import conditional_spline, spline\n",
        "import torch\n",
        "from torch.distributions.transforms import AffineTransform\n",
        "\n",
        "pyro.set_rng_seed(348)\n",
        "\n",
        "NxDist = Uniform(torch.zeros(1), torch.ones(1))     #A\n",
        "f_x = AffineTransform(loc=1., scale=100.0)    #B\n",
        "XDist = TransformedDistribution(NxDist, [f_x])    #C\n",
        "\n",
        "NyDist = Normal(torch.zeros(1), torch.ones(1))    #D\n",
        "f_y = conditional_spline(input_dim=1, context_dim=1)    #E\n",
        "YDist = ConditionalTransformedDistribution(NyDist, [f_y])    #F\n",
        "\n",
        "modules = torch.nn.ModuleList([f_y])    #H\n",
        "optimizer = torch.optim.Adam(modules.parameters(), lr=3e-3)    #H\n",
        "losses = []\n",
        "maxY = max(Y)    #I\n",
        "Ynorm = Y / maxY    #I\n",
        "for step in range(800):\n",
        "    optimizer.zero_grad()    #J\n",
        "    log_prob_x = XDist.log_prob(X)    #K\n",
        "    log_prob_y = YDist.condition(X).log_prob(Ynorm)    #L\n",
        "    loss = -(log_prob_x + log_prob_y).mean()    #M\n",
        "    loss.backward()    #M\n",
        "    optimizer.step()    #M\n",
        "    XDist.clear_cache()\n",
        "    YDist.clear_cache()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "plt.plot(losses[1:])    #N\n",
        "plt.title(\"Loss\")    #N\n",
        "plt.xlabel(\"step\")    #N\n",
        "plt.ylabel(\"loss\")    #N\n",
        "\n",
        "x_flow = XDist.sample(torch.Size([100,]))    #0\n",
        "y_flow = YDist.condition(x_flow).sample(torch.Size([100,])) * maxY    #0\n",
        "\n",
        "plt.title('Observed values of enzyme concentration X\\n and protein concentration Y')    #P\n",
        "plt.xlabel('X')    #P\n",
        "plt.ylabel('Y')    #P\n",
        "plt.xlim(0, 105)    #P\n",
        "plt.ylim(0, 120)    #P\n",
        "plt.scatter(X.squeeze(1), Y.squeeze(1), color='firebrick', label='Actual Data', alpha=0.5)  #P\n",
        "plt.scatter(x_flow.squeeze(1), y_flow.squeeze(), label='Generated values from trained model', alpha=0.5)    #P\n",
        "plt.legend()    #P\n",
        "plt.show()    #P\n"
      ],
      "metadata": {
        "id": "KRTV7rytRtnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_x.inv(torch.tensor([23.]))\n",
        "f_y.condition(torch.tensor([23.])).inv(torch.tensor([77.]))"
      ],
      "metadata": {
        "id": "QCwcpHOoWjOT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}