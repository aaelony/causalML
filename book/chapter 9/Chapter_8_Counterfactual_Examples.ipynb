{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altdeep/causalML/blob/master/book/chapter%208/Chapter_8_Counterfactual_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieEgsZtpNqLZ"
      },
      "outputs": [],
      "source": [
        "!pip install pyro-ppl\n",
        "!pip install dowhy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVChMdP1MtBT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "import torch.distributions.constraints as constraints\n",
        "\n",
        "from dowhy import gcm\n",
        "\n",
        "import pyro\n",
        "from pyro import deterministic, param, sample\n",
        "from pyro.contrib.autoname import scope\n",
        "from pyro.distributions import Normal\n",
        "from pyro.poutine import condition, do, reparam\n",
        "\n",
        "from pyro.optim import Adam\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V12FTgmG8wot"
      },
      "source": [
        "DoWhy GCM full model ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jp3z2Sd80Kb"
      },
      "outputs": [],
      "source": [
        "Z = np.random.normal(loc=0, scale=1, size=10000)\n",
        "X = 2 * Z + np.random.normal(loc=0, scale=1, size=10000)\n",
        "Y = 3 * X - 2 * Z + np.random.normal(loc=0, scale=1, size=10000)\n",
        "training_data = pd.DataFrame(data=dict(X=X, Y=Y, Z=Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzda19QE9dmM"
      },
      "outputs": [],
      "source": [
        "causal_model = gcm.InvertibleStructuralCausalModel(nx.DiGraph([(\"Z\", \"X\"), (\"X\", \"Y\"), (\"Z\", \"Y\")]))\n",
        "causal_model.set_causal_mechanism(\"Z\", gcm.EmpiricalDistribution())\n",
        "causal_model.set_causal_mechanism(\"X\", gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))\n",
        "causal_model.set_causal_mechanism(\"Y\", gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))\n",
        "gcm.fit(causal_model, training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIBMQ0Dr_lv0"
      },
      "outputs": [],
      "source": [
        "gcm.counterfactual_samples(\n",
        "    causal_model,\n",
        "    {'X': lambda x :2},\n",
        "    observed_data=pd.DataFrame(data=dict(Z=[1], X=[-1], Y=[1]))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ8QkRyYAnRx"
      },
      "source": [
        "Given our equations:\n",
        "\n",
        "\\begin{align}\n",
        "Z &= N_z\\\\\n",
        "X &= 2 * Z + N_x\\\\\n",
        "Y &= 3 * X - 2 * Z + N_y\n",
        "\\end{align}\n",
        "\n",
        "If X is -1.0, Y is 1.0, and Z is 1.0, then we have:\n",
        "\n",
        "\\begin{align} \n",
        "1 &= N_z\\\\\n",
        "-1 &= 2 * Z + N_x\\\\\n",
        "1 &= 3 * X - 2 * Z + N_y\n",
        "\\end{align}\n",
        "\n",
        "That's three equations and three unknowns, so we can solve for $N_z$, $N_x$, and $N_y$ directly, and get $N_z = 1, N_x = -3, N_y = 6$\n",
        "\n",
        "In the counterfactual world, we intervene and set X to 2.  The intervention operation changes the SCM to:\n",
        "\n",
        "\\begin{align}\n",
        "Z &= N_z\\\\\n",
        "X &= 2 \\\\\n",
        "Y &= 3 * X - 2 * Z + N_y\n",
        "\\end{align}\n",
        "\n",
        "Finally, we plug in values of Z we solved for.\n",
        "\n",
        "\\begin{align}\n",
        "Z &= 1\\\\\n",
        "X &= 2 \\\\\n",
        "Y &= 3 * X - 2 * Z + 6\n",
        "\\end{align}\n",
        "\n",
        "So Y is 3 * 2 - 2 * 1 + 6 =  10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRz_RlunAS9A"
      },
      "source": [
        "Try to make it work in degenerative case.  Should work with a little noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_6yvLCmU4dn"
      },
      "outputs": [],
      "source": [
        "def f_Z(Nz):\n",
        "    Z = Nz\n",
        "    return Z\n",
        "\n",
        "def f_X(Z, Nx):\n",
        "    X = Z + Nx\n",
        "    return X\n",
        "\n",
        "def f_Y(X, Z, Ny):\n",
        "    Y = 3 * X  -2 * Z + Ny\n",
        "    return Y\n",
        "\n",
        "def model():\n",
        "    Nz = sample(\"Nz\", Normal(0.0, 1.0))\n",
        "    Nx = sample(\"Nx\", Normal(0.0, 1.0))\n",
        "    Ny = sample(\"Ny\", Normal(0.0, 1.0))\n",
        "    Z = sample(\"Z\", Normal(f_Z(Nz), .001))\n",
        "    X = sample(\"X\", Normal(f_X(Z, Nx), .001))\n",
        "    Y = sample(\"Y\", Normal(f_Y(X, Z, Ny), .001))\n",
        "    return Z, X, Y\n",
        "\n",
        "def guide():\n",
        "    mu_z = param(\"μ_z\", torch.tensor(1.0))\n",
        "    scale_z = param(\"σ_z\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    mu_x = param(\"μ_x\", torch.tensor(1.0))\n",
        "    scale_x = param(\"σ_x\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    mu_y = param(\"μ_y\", torch.tensor(1.0))\n",
        "    scale_y = param(\"σ_y\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    Nz = sample(\"Nz\", Normal(mu_z, scale_z))\n",
        "    Nx = sample(\"Nx\", Normal(mu_x, scale_x))\n",
        "    Ny = sample(\"Ny\", Normal(mu_y, scale_y))\n",
        "    \n",
        "    return Z, X, Y\n",
        "\n",
        "soften = reparam(config=pyro.infer.reparam.AutoReparam())\n",
        "cond_model = condition(\n",
        "    model,\n",
        "    {\"X\": tensor(-1.0), \"Y\": tensor(1.0), \"Z\": tensor(1.0)}\n",
        ")\n",
        "\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# setup the optimizer\n",
        "optimizer = Adam({\"lr\": 0.01})\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(cond_model, guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "# do gradient steps\n",
        "losses= []\n",
        "M = 20000\n",
        "for step in range(M):\n",
        "    loss = svi.step()\n",
        "    losses.append(loss)\n",
        "    if step % 1000 == 0:\n",
        "        print(\"loss: \", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bizDPuVRnZdp"
      },
      "source": [
        "Now trying it when Z is unobserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqSjAqsUzzXR"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(len(losses)), losses)\n",
        "\n",
        "# grab the learned variational parameters\n",
        "μ_z_post = pyro.param(\"μ_z\").item()\n",
        "σ_z_post = pyro.param(\"σ_z\").item()\n",
        "μ_x_post = pyro.param(\"μ_x\").item()\n",
        "σ_x_post = pyro.param(\"σ_x\").item()\n",
        "μ_y_post = pyro.param(\"μ_y\").item()\n",
        "σ_y_post = pyro.param(\"σ_y\").item()\n",
        "\n",
        "print(μ_z_post, σ_z_post, μ_x_post, σ_x_post, μ_y_post, σ_y_post)\n",
        "print(\"Expect: N_z = 1, N_x = -3, N_y = 6\")\n",
        "#plt.hist([float(cf_model()[2]) for _ in range(1000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lqMiXOSEVUb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def model():\n",
        "    Nz = sample(\"Nz\", Normal(μ_z_post, σ_z_post))\n",
        "    Nx = sample(\"Nx\", Normal(μ_x_post, σ_x_post))\n",
        "    Ny = sample(\"Ny\", Normal(μ_y_post, σ_y_post))\n",
        "    Z = deterministic(\"Z\", f_Z(Nz))\n",
        "    X = deterministic(\"X\", f_X(Z, Nx))\n",
        "    Y = deterministic(\"Y\", f_Y(X, Z, Ny))\n",
        "    return Z, X, Y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew4EMly8tp7B"
      },
      "source": [
        "Now trying with Z unobserved.  Now the values of Nx, Ny, and Nz are not known with certainty.  But we can model them probabilistically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RjXBF6LGdhH"
      },
      "outputs": [],
      "source": [
        "def guide():\n",
        "    mu_z = param(\"μ_z\", torch.tensor(1.0))\n",
        "    scale_z = param(\"σ_z\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    mu_x = param(\"μ_x\", torch.tensor(1.0))\n",
        "    scale_x = param(\"σ_x\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    mu_y = param(\"μ_y\", torch.tensor(1.0))\n",
        "    scale_y = param(\"σ_y\", torch.tensor(1.0),\n",
        "                        constraint=constraints.positive)\n",
        "    Nz = sample(\"Nz\", Normal(mu_z, scale_z))\n",
        "    Nx = sample(\"Nx\", Normal(mu_x, scale_x))\n",
        "    Ny = sample(\"Ny\", Normal(mu_y, scale_y))\n",
        "    Z = sample(\"Z\", Normal(Nz, .001))\n",
        "    \n",
        "    return Z, X, Y\n",
        "\n",
        "soften = reparam(config=pyro.infer.reparam.AutoReparam())\n",
        "cond_model = condition(\n",
        "    model,\n",
        "    {\"X\": tensor(-1.0), \"Y\": tensor(1.0)}\n",
        ")\n",
        "\n",
        "pyro.clear_param_store()\n",
        "\n",
        "# setup the optimizer\n",
        "optimizer = Adam({\"lr\": 0.005})\n",
        "\n",
        "# setup the inference algorithm\n",
        "svi = SVI(cond_model, guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "# do gradient steps\n",
        "losses= []\n",
        "M = 20000\n",
        "for step in range(M):\n",
        "    loss = svi.step()\n",
        "    losses.append(loss)\n",
        "    if step % 1000 == 0:\n",
        "        print(\"loss: \", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDp4yFA9uZR0"
      },
      "source": [
        "Due to properties of Gaussian distibutions, P(Nx, Ny, Nz | X, Y) is a multivariate Gaussian (can confirm on stats site).\n",
        "\n",
        "A more general confirmation is to match moments.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "E(N_y) &= 3 - E(N_x)\\\\\n",
        "var(N_y) &= var(N_x)\\\\\n",
        "E(N_z) &= -(1 + E(N_x))/2\\\\\n",
        "var(N_z) &= var(N_x)/4\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx2K8woS4DlS"
      },
      "outputs": [],
      "source": [
        "μ_z_post = pyro.param(\"μ_z\").item()\n",
        "σ_z_post = pyro.param(\"σ_z\").item()\n",
        "μ_x_post = pyro.param(\"μ_x\").item()\n",
        "σ_x_post = pyro.param(\"σ_x\").item()\n",
        "μ_y_post = pyro.param(\"μ_y\").item()\n",
        "σ_y_post = pyro.param(\"σ_y\").item()\n",
        "\n",
        "print(\"Expect u_y + u_x = 3.  Summing I get \" + str(round(μ_y_post + μ_x_post, 2)))\n",
        "print(\"Expect σ_x - σ_y = 0.  I get \" + str(round(σ_x_post + σ_y_post, 4)))\n",
        "print(\"E(N_z) + (1 + E(N_x))/2 = 0.  I get \" + str(round(μ_z_post + .5 * (1 + μ_x_post),2)))\n",
        "print(\"var(N_z) - var(N_x)/4 = 0.  I get \" + str(round(σ_z_post**2 - σ_x_post**2/4, 4)))\n",
        "\n",
        "print(\n",
        "    round(μ_z_post, 2),\n",
        "    round(σ_z_post, 4), \n",
        "    round(μ_x_post, 2),\n",
        "    round(σ_x_post, 4),\n",
        "    round(μ_y_post, 2),\n",
        "    round(σ_y_post, 4),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer.discrete import infer_discrete\n",
        "from pyro.distributions import Bernoulli\n",
        "def model():\n",
        "    Nx = sample(\"Nx\", Bernoulli(.5))\n",
        "    Ny = sample(\"Ny\", Bernoulli(.5))\n",
        "    X = sample(\"X\", Bernoulli(Ny))\n",
        "    Y = sample(\"Y\", Bernoulli(X*Ny + (1.-X)(1.-Ny)))\n",
        "    return Nx, Ny, X, Y\n",
        "\n",
        "cond_model = pyro.condition(model, {\"X\": 1.0, \"Y\": 1.0})\n",
        "sampler = infer_discrete(cond_model, first_available_dim=-1)\n",
        "sampler()\n"
      ],
      "metadata": {
        "id": "f3dMCT60ccNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
        "\n",
        "@config_enumerate\n",
        "def model():\n",
        "    p = pyro.param(\"p\", torch.randn(3, 3).exp(), constraint=constraints.simplex)\n",
        "    x = pyro.sample(\"x\", dist.Categorical(p[0]))\n",
        "    y = pyro.sample(\"y\", dist.Categorical(p[x]))\n",
        "    z = pyro.sample(\"z\", dist.Categorical(p[y]))\n",
        "    print(f\"  model x.shape = {x.shape}\")\n",
        "    print(f\"  model y.shape = {y.shape}\")\n",
        "    print(f\"  model z.shape = {z.shape}\")\n",
        "    return x, y, z\n",
        "\n",
        "def guide():\n",
        "    pass\n",
        "\n",
        "serving_model = infer_discrete(model, first_available_dim=-1)\n",
        "x, y, z = serving_model()"
      ],
      "metadata": {
        "id": "mvKV1O4MpJhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLe1XupYREAf0XsQb4JAvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}